{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2zoWWXM3zpX"
      },
      "source": [
        "# Sumarização de Múltiplos Documentos Científicos Usando o Dataset SurveySum\n",
        "\n",
        "## 1. Objetivo do Projeto\n",
        "O objetivo do projeto será desenvolver um sistema que realiza sumarização de múltiplos documentos científicos nas áreas de Inteligência Artificial (IA), Processamento de Linguagem Natural (PLN) e Aprendizado de Máquina (ML), utilizando o dataset SurveySum. O foco será em criar uma solução que possa gerar uma seção de revisão de literatura com base em um conjunto de artigos científicos relacionados a um tema específico.\n",
        "\n",
        "## 2. Escopo do Projeto\n",
        "Este projeto está dividido em etapas práticas e definidas:\n",
        "\n",
        "### Exploração do Dataset SurveySum:\n",
        "\n",
        "* Compreender a estrutura do SurveySum e selecionar uma pequena parte do dataset (por exemplo, algumas seções de surveys) para treinar e testar o modelo.\n",
        "\n",
        "### Modelo de Sumarização:\n",
        "\n",
        "* Utilizar um modelo de linguagem pré-treinado Pegasus para a tarefa de sumarização abstrativa. Esses modelos são eficazes para resumir textos longos e podem ser ajustados para essa tarefa.\n",
        "* Implementar um pipeline simples de retrieval + summarization:\n",
        "** Recuperação: Coletar e segmentar os artigos científicos relacionados ao tema\n",
        "** Sumarização: Alimentar esses textos segmentados no modelo de linguagem para gerar o resumo (seção do survey).\n",
        "\n",
        "###  Avaliação da Qualidade:\n",
        "\n",
        "* Avaliar a qualidade das sumarizações geradas com base em métricas automáticas simples, como ROUGE (para medir a sobreposição entre os textos de referência e os textos gerados) ou uma avaliação manual, comparando com as seções do survey original.\n",
        "* Para simplificar, será testado o modelo em apenas algumas seções do survey para verificar se o modelo consegue gerar resumos coesos e relevantes.\n",
        "\n",
        "### Relatório Final:\n",
        "\n",
        "* Documentar o pipeline implementado e os resultados obtidos, discutindo as limitações e sugerindo melhorias. O foco será na eficácia do modelo em gerar resumos adequados e coesos com base em múltiplos documentos científicos.\n",
        "* O relatório pode incluir uma análise dos resultados e a proposta de como o projeto poderia ser expandido para tarefas mais complexas no futuro.\n",
        "\n",
        "## 3. Ferramentas e Tecnologias\n",
        "* Dataset: SurveySum (disponível no Hugging Face Datasets).\n",
        "* Modelo de Sumarização: Pegasus.\n",
        "* Ambiente de Desenvolvimento: Google Colab (para experimentos com modelos de linguagem e acesso ao dataset).\n",
        "* Avaliação: Métricas como ROUGE para medir a qualidade dos resumos gerados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_moJbPsxxn3M"
      },
      "source": [
        "# Configuração Inicial e Importação de Pacotes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFrh_CiAxVb0",
        "outputId": "06db6972-5e4d-436d-9ed0-d4b97d30192b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Instalar bibliotecas específicas (executar no Colab)\n",
        "!pip install transformers datasets sentence-transformers rouge_score\n",
        "\n",
        "# Importação das bibliotecas necessárias\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl6XAa5L8VuW",
        "outputId": "7d25c2fc-bfdc-4785-9410-97b499ded7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cok11w74h2R"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1g3wxyVYXFV"
      },
      "source": [
        "### A. Dataset SurveySum\n",
        "\n",
        "#### 1. Estrutura do Dataset:\n",
        "\n",
        "O comando print(dataset) exibe a estrutura do dataset carregado. Nesse caso, a saída mostra que o dataset SurveySum contém um conjunto de dados chamado train (treinamento) com 79 entradas.\n",
        "#### 2. Campos do Dataset:\n",
        "\n",
        "* Cada entrada do dataset tem os seguintes campos:\n",
        "** survey_id: Identificador único para cada survey (ou seção de survey).\n",
        "** survey_title: Título da survey, que indica o tópico geral da seção.\n",
        "** section_title: Título da seção específica dentro do survey.\n",
        "** generated_section_text: Texto gerado automaticamente para a seção, provavelmente criado por modelos de linguagem ou humanos.\n",
        "** citations: Referências dos artigos utilizados para compor a seção de survey.\n",
        "** section_text_in_survey: Texto de referência para a seção, que representa o resumo ideal dos artigos citados.\n",
        "\n",
        "#### 3. Significado dos Dados:\n",
        "\n",
        "Esses campos são organizados para ajudar em tarefas de sumarização multidocumento, onde o objetivo é gerar uma seção de survey coesa a partir de múltiplos artigos. O campo section_text_in_survey pode ser usado como resumo de referência para comparar a qualidade de resumos gerados automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf8rvQXxXUog",
        "outputId": "7083ccab-dee6-43b6-e46d-ca3b6db1316e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura do Dataset SurveySum:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['survey_id', 'survey_title', 'section_title', 'generated_section_text', 'citations', 'section_text_in_survey'],\n",
            "        num_rows: 79\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Importa a função 'load_dataset' da biblioteca 'datasets' para carregar datasets do Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Carrega o dataset \"SurveySum\" da plataforma Hugging Face.\n",
        "# Este dataset foi criado especificamente para sumarização multidocumento, onde o objetivo é gerar uma seção de survey\n",
        "# (resumo de múltiplos artigos) a partir de artigos científicos relacionados.\n",
        "dataset = load_dataset(\"unicamp-dl/SurveySum\")\n",
        "\n",
        "# Exibe a estrutura geral do dataset carregado, mostrando seus diferentes conjuntos (por exemplo, train, test).\n",
        "# Esse print ajuda a visualizar as características principais do dataset, como os campos e a quantidade de amostras.\n",
        "print(\"Estrutura do Dataset SurveySum:\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vdRDKKkv87N"
      },
      "source": [
        "### B. Conteúdo da Estrutura de Saída do Dataset\n",
        "\n",
        "Este código ajuda a verificar o conteúdo e a estrutura de cada campo de uma entrada do SurveySum. A exibição organizada facilita a leitura e compreensão das informações, especialmente no caso de textos longos. Isso é fundamental para um entendimento inicial do dataset, permitindo identificar rapidamente as referências e a estrutura dos dados que serão utilizados no projeto.\n",
        "Ele é útil para verificar a estrutura e o conteúdo de um exemplo típico do dataset antes de implementar outros passos do pipeline. Abaixo está uma explicação detalhada de cada parte do código e o que esperar na saída.\n",
        "\n",
        "#### 1. Exibição dos Campos Principais da Entrada\n",
        "\n",
        "* A primeira parte do código armazena a primeira entrada do dataset (dataset['train'][2]) e exibe os campos principais com uma formatação clara e organizada:\n",
        "** Survey ID: Exibe o identificador único da survey.\n",
        "** Survey Title: Exibe o título do survey.\n",
        "** Section Title: Exibe o título da seção específica do survey.\n",
        "* Esses campos permitem identificar o tema e a seção do survey que está sendo exibido, fornecendo contexto inicial.\n",
        "\n",
        "#### 2. Exibição do Texto Gerado (Generated Section Text)\n",
        "\n",
        "* O campo generated_section_text contém uma estrutura que armazena os chunks de texto associados a referências bibliográficas, cada um identificado por um código (BIBREF).\n",
        "* O código verifica se existem chunks na estrutura autosurvey_t5_3b_10_chunks. Caso existam, exibe cada chunk com uma referência (BIBREF) e um trecho do texto associado (limitado a 100 caracteres para simplificar a visualização).\n",
        "\n",
        "Exemplo de Saída:\n",
        "\n",
        "**Referência: BIBREF14 | Texto: ...representative example, the Chain-of-Thought prompts largely improve the performance...**\n",
        "\n",
        "Essa parte ajuda a entender como os chunks referenciam artigos específicos e como são utilizados para compor a seção do survey.\n",
        "\n",
        "#### 3. Exibição das Citações (Citations)\n",
        "\n",
        "* Este código exibe o conjunto completo de 266 citações (BIBREF), que representam todas as referências bibliográficas utilizadas no dataset SurveySum.\n",
        "Independentemente da entrada selecionada, o número de citações exibido será sempre o mesmo, pois o conjunto de citações reflete todas as referências que podem ser associadas aos chunks ao longo de todas as seções do survey.\n",
        "\n",
        "Citations:\n",
        "  1. BIBREF0\n",
        "  2. BIBREF1\n",
        "  ...\n",
        "  Total de citações: 266\n",
        "\n",
        "* Embora cada entrada utilize apenas uma parte das 266 citações em seus chunks, o código exibe todas as possíveis citações do dataset para fornecer uma visão geral das referências disponíveis.\n",
        "\n",
        "#### 4. Exibição do Texto de Referência da Seção (Section Text in Survey)\n",
        "\n",
        "* O texto de referência representa o resumo \"gold standard\" para a seção, criado para ser o modelo ideal de sumarização.\n",
        "\n",
        "* A caixa de texto permite visualizar de maneira clara o texto de referência completo da seção, que é o objetivo final de uma sumarização precisa.\n",
        "\n",
        "Finalidade e Benefícios da Estrutura de Saída\n",
        "Este código ajuda a verificar o conteúdo e a estrutura de cada campo de uma entrada do SurveySum. A exibição organizada facilita a leitura e compreensão das informações, especialmente no caso de textos longos. Isso é fundamental para um entendimento inicial do dataset, permitindo identificar rapidamente as referências e a estrutura dos dados que serão utilizados no projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZbiF50-D2Jj",
        "outputId": "93e2c0bc-ae7f-4eff-f0ab-26079fa31952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Primeira Entrada do Dataset de Treinamento (SurveySum) ===\n",
            "\n",
            "Survey ID: 2309.15402v1\n",
            "\n",
            "Survey Title:\n",
            "  A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future\n",
            "\n",
            "Section Title:\n",
            "  Methods::XoT Structural Variants::Tree Structure\n",
            "\n",
            "Generated Section Text:\n",
            "  Referências e Chunks de Texto:\n",
            "    1. Referência: BIBREF14 | Texto: ...representative example, the Chain-of-Thought prompts largely improve the performance on tasks tha...\n",
            "    2. Referência: BIBREF16 | Texto: ...that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To...\n",
            "    3. Referência: BIBREF80 | Texto: ...aug 2022. [14] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha...\n",
            "\n",
            "Citations:\n",
            "  1. BIBREF0\n",
            "  2. BIBREF1\n",
            "  3. BIBREF10\n",
            "  4. BIBREF100\n",
            "  5. BIBREF101\n",
            "  6. BIBREF102\n",
            "  7. BIBREF103\n",
            "  8. BIBREF104\n",
            "  9. BIBREF105\n",
            "  10. BIBREF106\n",
            "  ...\n",
            "  Total de citações: 266\n",
            "\n",
            "Section Text in Survey (Referência):\n",
            "┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
            "│ The original chain structure inherently limits the scope of exploration. Through the incorporation of tree structures and tree search algorithms, models gain th │\n",
            "│ e capability to efficiently explore and backtrack during the reasoning process BIBREF80 , BIBREF16 , as shown in Figure FIGREF24 (e). Combined with self-assessm │\n",
            "│ ent of intermediate thoughts, models can achieve global optimum solutions. However, the current tree-of-thought has considerable limitations on task selection a │\n",
            "│ nd requires specific prompt designing for each task, which hinders its widespread application. SoT BIBREF14 is another variant of the tree structure, which deco │\n",
            "│ mposes a problem into subproblems that can be processed in parallel and solved at the same time to speed up reasoning. However, its utility is restricted to par │\n",
            "│ allel decomposable problems and is not suited for complex reasoning tasks.                                                                                       │\n",
            "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "# Esse código tem a finalidade de exibir as primeiras linhas do dataset SurveySum,\n",
        "# apresentando os campos principais da primeira entrada para uma inspeção inicial.\n",
        "\n",
        "# Exibir a primeira entrada do conjunto de treinamento do SurveySum de forma organizada\n",
        "print(\"=== Primeira Entrada do Dataset de Treinamento (SurveySum) ===\\n\")\n",
        "\n",
        "# Armazena a primeira entrada do dataset de treinamento para visualização organizada\n",
        "primeira_entrada = dataset['train'][2]\n",
        "\n",
        "# Exibe cada campo com formatação organizada\n",
        "print(\"Survey ID:\", primeira_entrada['survey_id'])\n",
        "print(\"\\nSurvey Title:\")\n",
        "print(f\"  {primeira_entrada['survey_title']}\")\n",
        "print(\"\\nSection Title:\")\n",
        "print(f\"  {primeira_entrada['section_title']}\")\n",
        "\n",
        "# Exibe o texto gerado, se disponível e estruturado como dicionário, com extração dos principais chunks de texto\n",
        "print(\"\\nGenerated Section Text:\")\n",
        "generated_text = primeira_entrada.get('generated_section_text')\n",
        "if isinstance(generated_text, dict) and 'autosurvey_t5_3b_10_chunks' in generated_text:\n",
        "    autosurvey = generated_text['autosurvey_t5_3b_10_chunks']\n",
        "    if 'references_sent_to_gpt' in autosurvey:\n",
        "        print(\"  Referências e Chunks de Texto:\")\n",
        "        for i, ref_chunk in enumerate(autosurvey['references_sent_to_gpt'], 1):\n",
        "            bibref = ref_chunk.get('bibref', 'Sem referência')\n",
        "            chunk_text = ref_chunk.get('chunk', 'Texto não disponível')\n",
        "           # print(f\"    {i}. Referência: {bibref} | Texto: {chunk_text}\")  # Exibe o texto completo\n",
        "\n",
        "            print(f\"    {i}. Referência: {bibref} | Texto: {chunk_text[:100]}...\")  # Limita a exibição a 100 caracteres\n",
        "    else:\n",
        "        print(\"  (Referências e chunks de texto não disponíveis)\")\n",
        "else:\n",
        "    print(\"  (Texto gerado não disponível ou não estruturado conforme esperado)\")\n",
        "\n",
        "# Exibe as citações de forma numerada\n",
        "print(\"\\nCitations:\")\n",
        "\n",
        "# Obtém as chaves das primeiras 10 citações do dicionário de citações\n",
        "citation_keys = list(primeira_entrada['citations'].keys())[:10]\n",
        "total_citations = len(primeira_entrada['citations'])  # Total de citações\n",
        "\n",
        "# Exibe até as primeiras 10 citações\n",
        "for i, citation_key in enumerate(citation_keys, 1):\n",
        "    print(f\"  {i}. {citation_key}\")  # Exibe cada chave de citação numerada\n",
        "\n",
        "# Indica que existem mais citações, se o total for maior que 10\n",
        "if total_citations > 10:\n",
        "    print(\"  ...\")  # Indica que há mais citações\n",
        "    print(f\"  Total de citações: {total_citations}\")  # Exibe o número total de citações\n",
        "\n",
        "# Exibe o texto de referência da seção em uma \"caixa de texto\" para facilitar a leitura\n",
        "print(\"\\nSection Text in Survey (Referência):\")\n",
        "\n",
        "# Verifica se o texto de referência está disponível e é uma string\n",
        "if isinstance(primeira_entrada.get('section_text_in_survey'), str) and primeira_entrada['section_text_in_survey']:\n",
        "    # Limita a exibição a 500 caracteres e quebra em várias linhas\n",
        "    text = primeira_entrada['section_text_in_survey'][::]\n",
        "    box_width = 160  # Largura da caixa de texto\n",
        "\n",
        "    # Divide o texto em linhas de exatamente 'box_width' caracteres\n",
        "    lines = [text[i:i + box_width].ljust(box_width) for i in range(0, len(text), box_width)]\n",
        "\n",
        "    # Imprime o texto dentro de uma caixa com bordas alinhadas\n",
        "    print(\"┌\" + \"─\" * (box_width+2) + \"┐\")\n",
        "    for line in lines:\n",
        "        print(\"│ \" + line + \" │\")\n",
        "    print(\"└\" + \"─\" * (box_width +2) + \"┘\")\n",
        "else:\n",
        "    print(\"  (Texto de referência não disponível)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9ZpsRP5iDS"
      },
      "source": [
        "### C. Exibição Completa de Citações e Chunks Associados no Dataset SurveySum\n",
        "\n",
        "Este código tem como objetivo exibir todas as citações presentes no dataset SurveySum, juntamente com os chunks de texto associados a cada uma delas, se disponíveis. Ele é importante para:\n",
        "\n",
        "#### 1. Verificação de Referências e Conteúdo Associado:\n",
        "\n",
        "Ao mostrar cada citação e seus chunks, o código permite uma análise detalhada da relação entre as referências bibliográficas (BIBREF) e os textos extraídos. Isso ajuda a entender a extensão e profundidade do uso de cada citação em diferentes partes do survey.\n",
        "#### 2. Preparação para Sumarização:\n",
        "\n",
        "Esse processo é essencial para a etapa de sumarização multidocumento, pois permite identificar os trechos de texto relevantes associados a cada citação. Esse é um passo importante para estruturar a entrada que será processada pelo modelo de sumarização.\n",
        "#### 3. Organização e Acesso aos Dados:\n",
        "\n",
        "Armazenar os chunks em um dicionário facilita o acesso e manipulação dos dados, permitindo que outras operações (como a criação de resumos) sejam realizadas de forma mais eficiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVsP_6bV6CM1",
        "outputId": "a15a3f22-1d8f-44ae-819a-4cf3425d7f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exibindo Todas as Citações e Seus Chunks Correspondentes ===\n",
            "\n",
            "\n",
            "Referência: BIBREF358\n",
            "  Chunk 1: ...many research areas, including 1) Computer-based musical analysis (Volk et al., 2011; Meredith, 2016) such as using computers to analyse the struct...\n",
            "\n",
            "Referência: BIBREF179\n",
            "  Chunk 1: ...collected for training and evaluating melody harmonization. In addition to conducting a subjective evaluation, we employed in total six objective m...\n",
            "  Chunk 2: ...Island, Korea, pages 1–40. ACL. Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models for natural...\n",
            "\n",
            "Referência: BIBREF306\n",
            "  Chunk 1: ...a given sentiment. This paper presents a generative Deep Learning model that can be directed to compose music with a given sentiment. Besides music...\n",
            "\n",
            "Referência: BIBREF355\n",
            "  Chunk 1: ...Association 1(3). [Bertin-Mahieux et al. 2011] Bertin-Mahieux, T.; Ellis, D. P.; Whitman, B.; and Lamere, P. 2011. The million song dataset. 12th I...\n",
            "\n",
            "Referência: BIBREF199\n",
            "  Chunk 1: ...Excellence Scholarship program. GPUs used in this research were donated by NVIDIA. 8. REFERENCES [1] Moray Allan and Christopher Williams. Harmonis...\n",
            "  Chunk 2: ...NLP tasks, particularly for sentiment analysis. For instance, existing work has shown that linguistic knowledge including part-of-speech tag (Qian ...\n",
            "  Chunk 3: A Survey of Data Augmentation Approaches for NLP Steven Y. Feng∗, 1 Varun Gangal∗, 1 Jason Wei†, 2 Sarath Chandar,3 Soroush Vosoughi,4 Teruko Mitamura...\n",
            "\n",
            "Referência: BIBREF354\n",
            "  Chunk 1: ...on the result, fine-tunes them in note-level. A listening test with professional pianists shows that our model achieves a more human-like expressiv...\n",
            "\n",
            "Referência: BIBREF357\n",
            "  Chunk 1: ...note to be off. Using regularization methods such as weight decay has not proven efficient. We believe that this is due to the sparsity of the vect...\n",
            "\n",
            "Referência: BIBREF356\n",
            "  Chunk 1: ...FUTURE OF THE DATASET Time will tell how useful the MSD proves to be, but here are our thoughts regarding what will become of this data. We have as...\n",
            "\n",
            "Referência: BIBREF312\n",
            "  Chunk 1: ...proposed ficta hurt the harmony. One of the main advantages of the music21 framework is making such observations on large collections of musical da...\n",
            "\n",
            "Referência: BIBREF316\n",
            "  Chunk 1: ...future work. II. RELATED WORK A. Singing Voice Dataset Singing datasets of various sizes and annotated contents are available for research purposes...\n",
            "\n",
            "Referência: BIBREF70\n",
            "  Chunk 1: Deductive Verification of Chain-of-Thought Reasoning Zhan Ling1∗ Yunhao Fang1∗ Xuanlin Li1 Zhiao Huang1 Mingu Lee2 Roland Memisevic2 Hao Su1 1UC San D...\n",
            "  Chunk 2: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing Pengfei Liu Carnegie Mellon University pliu3@c...\n",
            "  Chunk 3: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing Pengfei Liu Carnegie Mellon University pliu3@c...\n",
            "  Chunk 4: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing Pengfei Liu Carnegie Mellon University pliu3@c...\n",
            "\n",
            "Referência: BIBREF104\n",
            "  Chunk 1: ...CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge. Building on top of G...\n",
            "  Chunk 2: ...NLP tasks, named entity recognition (NER) does predictions on the token level. That is, for each token in the sentence, NER models predict a label ...\n",
            "  Chunk 3: ...template-based method. The template we use here is “⟨xi:j⟩ is a ⟨yk⟩ entity\". Figure 2: Overview of NER methods. rely on self training on external ...\n",
            "  Chunk 4: ...template-based method. The template we use here is “⟨xi:j⟩ is a ⟨yk⟩ entity\". Figure 2: Overview of NER methods. rely on self training on external ...\n",
            "  Chunk 5: ...template-based method. The template we use here is “⟨xi:j⟩ is a ⟨yk⟩ entity\". Figure 2: Overview of NER methods. rely on self training on external ...\n",
            "  Chunk 6: ...the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4115– 4128, Hong Kong, China. Association for Computati...\n",
            "\n",
            "Referência: BIBREF71\n",
            "  Chunk 1: ...of input x, the previously generated output yt, the feedback generated fbt, and the refinement yt+1. Few-shot prompts used for FEEDBACK and REFINE ...\n",
            "  Chunk 2: ...the question how could existing PLMs benefit training large-scale PLMs in future. Specifically, we introduce a pre-training framework named “knowle...\n",
            "  Chunk 3: ...can be a real contribution to training a model. 2 Related Work Prompting has been used both for zero-shot and fine-tuning based methods. Zero-shot ...\n",
            "\n",
            "Referência: BIBREF16\n",
            "  Chunk 1: ...and Y. Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents, 2023. [35] ...\n",
            "  Chunk 2: ...that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new fra...\n",
            "  Chunk 3: Universal Language Model Fine-tuning for Text Classification Jeremy Howard∗ fast.ai University of San Francisco j@fast.ai Sebastian Ruder∗ Insight Cen...\n",
            "  Chunk 4: Universal Language Model Fine-tuning for Text Classification Jeremy Howard∗ fast.ai University of San Francisco j@fast.ai Sebastian Ruder∗ Insight Cen...\n",
            "\n",
            "Referência: BIBREF166\n",
            "  Chunk 1: ...and Y. Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents, 2023. [35] ...\n",
            "  Chunk 2: ...sparse transformers. arXiv preprint arXiv:1909.00015, 2019. Zihang Dai, Zhilin Yang, Yiming Yang, William W Cohen, Jaime Carbonell, Quoc V Le, and ...\n",
            "  Chunk 3: ...relation R(X, Y ), and a natural language description d of R, we wish to evaluate whether T expresses R(X, Y ). We formulate this task as a textual...\n",
            "\n",
            "Referência: BIBREF81\n",
            "  Chunk 1: ...from questions in arithmetic, commonsense, and symbolic reasoning tasks (Wei et al., 2022). However, this “chain-of-thought” reasoning is a static ...\n",
            "  Chunk 2: ...Data Augmentation (CDA), in which a corpus is duplicated and augmented to remove bias, e.g. by swapping all inherently-gendered words in the copy. ...\n",
            "  Chunk 3: ...paragraph to improve NLP applications such as document classification, machine translation, question answering, etc. The combined evidence suggests...\n",
            "\n",
            "Referência: BIBREF82\n",
            "  Chunk 1: ...(GT) uses Chain-of-Thought reasoning with provided ground truth context, which tests reasoning ability over long contexts. Next, we add an element ...\n",
            "  Chunk 2: ...Linguistics. He He, Sheng Zha, and Haohan Wang. 2019. Unlearn dataset bias in natural language inference by fitting the residual. In Proceedings of...\n",
            "  Chunk 3: ...International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 43–54. Maria Pontiki, Dimitrios Galanis, Haris Papageorgiou, Io...\n",
            "  Chunk 4: ...In Proceedings of the 45th annual meeting of the association of computational linguistics, pages 440–447. Jacob Devlin, Ming-Wei Chang, Kenton Lee,...\n",
            "  Chunk 5: ...findings and infrastructure can help future work on designing new datasets, models and objective functions for pre-training. 1 Introduction Large p...\n",
            "\n",
            "Referência: BIBREF80\n",
            "  Chunk 1: ...determine the optimal response [14, 15]. Experiments were also conducted to evaluate the performance of different prompts [15]. The self-taught rea...\n",
            "  Chunk 2: ...aug 2022. [14] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency impro...\n",
            "  Chunk 3: Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology Ran Zmigrod1 Sabrina J. Mielke2 Hanna Wallach3 Ry...\n",
            "  Chunk 4: ...social media posts in English from communities banned for being offensive, abusive, or hateful. 2 HateBERT: Re-training BERT with Abusive Online Co...\n",
            "  Chunk 5: ...for MRC In light of recent advancements in NLP from large-scale pre-training, we use BERT (Devlin et al., 2019) as our sequence encoder. We first r...\n",
            "\n",
            "Referência: BIBREF127\n",
            "  Chunk 1: ...with a maximum search time of 200 seconds. We report the success rate of the optimal alias, and for the domains that time out, we show the success ...\n",
            "\n",
            "Referência: BIBREF14\n",
            "  Chunk 1: ...representative example, the Chain-of-Thought prompts largely improve the performance on tasks that require logical reasoning by simply providing a ...\n",
            "  Chunk 2: ...is often linear, (ii) for good performance with a linear classifier they must incorporate many handengineered features specific for the task; and (...\n",
            "\n",
            "Referência: BIBREF89\n",
            "  Chunk 1: ...also extend IBP to handle discrete perturbation sets, rather than the continuous ones used in vision. Second, can we train models that are robust i...\n",
            "  Chunk 2: ...of contextual calibration. Volatility of Few-shot Learning in NLP Recent work shows that when using masked language models such as BERT for zero-sh...\n",
            "\n",
            "Referência: BIBREF90\n",
            "  Chunk 1: ...adversarial examples to break NLP systems. Existing approaches mostly focused on adding labelpreserving perturbations to inputs, but with the effec...\n",
            "  Chunk 2: ...cross-lingual transfer for question generation and abstractive summarization. VECO (Luo et al., 2020) pretrains a variable cross-lingual pre-traini...\n",
            "  Chunk 3: ...language generation, but also natural language understanding (NLU), where they are largely used for unsupervised representation learning in pretrai...\n",
            "  Chunk 4: ...size and training data size of pre-trained models plays a significant role in the accuracy of models; pre-trained LMs such as BERT (Devlin et al., ...\n",
            "\n",
            "Referência: BIBREF91\n",
            "  Chunk 1: ...SQuAD reading comprehension task. Glockner et al. (2018) create an adversarial dataset from SNLI by using WordNet knowledge. Automatic methods (Iyy...\n",
            "  Chunk 2: ...Recent work has shown that large pre-trained language models (LM), trained with a masked language modeling (MLM) objective (Devlin et al., 2019; Li...\n",
            "\n",
            "Referência: BIBREF92\n",
            "  Chunk 1: ...automatically generate sentence pairs (§3.1) which are then manually verified (§3.2). 3.1 Generating Adversarial Examples In order to isolate the l...\n",
            "  Chunk 2: ...NAACL. Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and Armand Joulin. 2018. Advances in pre-training distributed word repres...\n",
            "\n",
            "Referência: BIBREF88\n",
            "  Chunk 1: ...given a handful of examples. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 96–108. Varun Kumar, Ha...\n",
            "  Chunk 2: ...Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the Nor...\n",
            "\n",
            "Referência: BIBREF87\n",
            "  Chunk 1: Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning Jason Wei Chengyu Huang Soroush Vosoughi Yu Cheng Shiqi...\n",
            "\n",
            "Referência: BIBREF86\n",
            "  Chunk 1: ...vision domain might not produce similar gains on NLP tasks, thus underlining the need to develop data augmentation methods specific to NLP tasks. R...\n",
            "  Chunk 2: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Languag...\n",
            "  Chunk 3: ...considering both classification and—for the first time—regression. First, we follow the route of prompt-based prediction, first developed by the GP...\n",
            "  Chunk 4: ...considering both classification and—for the first time—regression. First, we follow the route of prompt-based prediction, first developed by the GP...\n",
            "  Chunk 5: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Languag...\n",
            "  Chunk 6: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Languag...\n",
            "\n",
            "Referência: BIBREF21\n",
            "  Chunk 1: ...adaptive embedding space for which the task can be better solved. In [39] the embedding space is optimized to best support task-adaptive category p...\n",
            "  Chunk 2: ...(2019) introduced mBERT and XLM - masked language models trained on multiple languages, without any cross-lingual supervision. Lample and Conneau (...\n",
            "\n",
            "Referência: BIBREF20\n",
            "  Chunk 1: ...simple data augmentation. Comparison to other low-shot methods. We also compared to two recently proposed low-shot learning methods: matching netwo...\n",
            "\n",
            "Referência: BIBREF13\n",
            "  Chunk 1: ...knowledge, we are the first to comprehensively explore text editing techniques for data augmentation. We systematically evaluate EDA on five benchm...\n",
            "  Chunk 2: ...augmentation method for NLP, either now or in the future. Rather, we hope that our line of thought might inspire new approaches for universal or ta...\n",
            "  Chunk 3: ...1, respectively. 3.1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layer...\n",
            "  Chunk 4: ...of the NAACL, Main Conference, pages 152–159. ACL, June 2006. [27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable...\n",
            "\n",
            "Referência: BIBREF85\n",
            "  Chunk 1: ...labeling new instances with this class at the expense of the minority class. Moreover, imbalanced distribution of classes can complicate other comm...\n",
            "  Chunk 2: ...the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 4596–4604. PMLR. Taylor Shin, Y...\n",
            "  Chunk 3: ...multiple prompts for the same task, can boost quality and is more efficient than classic model ensembling. Finally, in Section 7, we investigate th...\n",
            "  Chunk 4: ...most model sizes. Prompt Design: Only a sequence of prompt IDs (500–2000 tokens) is required. the LM adapated versions work reliably across all mod...\n",
            "\n",
            "Referência: BIBREF84\n",
            "  Chunk 1: ...Mera, C., Arrieta, J., Orozco-Alzate, M., & Branch, J. (2015). A bag oversampling approach for class imbalance in multiple instance learning. In Pr...\n",
            "  Chunk 2: ...setting, outperforming GPT-3 on two SuperGLUE tasks with just 32 training samples. 1 Introduction Language model pretraining has had a tremendous i...\n",
            "  Chunk 3: ...with LSTM networks in (Neekhara et al., 2019). They operate in the vocabulary space and reprogram a model trained for one task to perform another t...\n",
            "  Chunk 4: ...setting, outperforming GPT-3 on two SuperGLUE tasks with just 32 training samples. 1 Introduction Language model pretraining has had a tremendous i...\n",
            "  Chunk 5: ...setting, outperforming GPT-3 on two SuperGLUE tasks with just 32 training samples. 1 Introduction Language model pretraining has had a tremendous i...\n",
            "\n",
            "Referência: BIBREF83\n",
            "  Chunk 1: ...larger true positive (TP) intercept. Thus, the classifier at that point is optimal under any distribution assumptions in tandem with that slope. Th...\n",
            "  Chunk 2: ...et al. Best practices for scientific computing. PLOS Biology 12, e1001745 (2014). 8. MIMIC-III Critical Care Database: Documentation and Website ht...\n",
            "  Chunk 3: Prefix-Tuning: Optimizing Continuous Prompts for Generation Xiang Lisa Li Stanford University xlisali@stanford.edu Percy Liang Stanford University pli...\n",
            "  Chunk 4: ...optimizes a small continuous task-specific vector (called the prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent tokens t...\n",
            "\n",
            "Referência: BIBREF79\n",
            "  Chunk 1: ...drop in accuracy. Our third contribution is counterfactual data augmentation (CDA): a generic methodology to mitigate bias in neural NLP tasks. For...\n",
            "  Chunk 2: ...Linguistics. Alexandra Chronopoulou, Christos Baziotis, and Alexandros Potamianos. 2019. An embarrassingly simple approach for transfer learning fr...\n",
            "  Chunk 3: ...al. (2018) rephrase several tasks as QA problems. Raffel et al. (2020) frame various problems as language modeling tasks, but their patterns only l...\n",
            "  Chunk 4: ...Linguistics. Alexandra Chronopoulou, Christos Baziotis, and Alexandros Potamianos. 2019. An embarrassingly simple approach for transfer learning fr...\n",
            "\n",
            "Referência: BIBREF78\n",
            "  Chunk 1: ...et al., 2015; Misra et al., 2016). For structured prediction, the work of Zhao et al. (2017) reduces bias by using corpus level constraints, but is...\n",
            "  Chunk 2: ...by pairing two random sentences, each from a different document. To increase the number of combinations of documents and to enhance medical-word re...\n",
            "\n",
            "Referência: BIBREF137\n",
            "  Chunk 1: ...2020). Outside of application-tailored augmentations, improvements are primarily reported on autoregressive models without unsupervised pretraining...\n",
            "  Chunk 2: ...scales well with large pre-trained LMs and large amounts of training data, reporting the best results on TACRED to date. 2 Related Work Textual Ent...\n",
            "\n",
            "Referência: BIBREF3\n",
            "  Chunk 1: ...indicates that results are not available. 1. Introduction Data augmentation is a widely used method for generating additional data to improve machi...\n",
            "\n",
            "Referência: BIBREF142\n",
            "  Chunk 1: ...2021 Analogous to typical data augmentations, NDA strategies are by definition domain and task specific. In this paper, we focus on natural images ...\n",
            "\n",
            "Referência: BIBREF175\n",
            "  Chunk 1: ...& Taylor, 2017; Park et al., 2019; Zhong et al., 2017), and adversarial noise (Szegedy et al., 2013). Mixup (Zhang et al., 2017) and Sample Pairing...\n",
            "  Chunk 2: ...Introduction Pre-trained transformer language models (GPT [9], XLNet [17], XLM [7], BERT [3]) have demonstrated State-of-the-Art (SOTA) results for...\n",
            "  Chunk 3: ...to enhance content preservation. Shang et al. (2019) propose a semi-supervised model combining parallel data with large amounts of non-parallel dat...\n",
            "\n",
            "Referência: BIBREF143\n",
            "  Chunk 1: ...use FastAutoAugment for their best result. • CPC v1 and v2 (Oord et al., 2018; Hénaff et al., 2019) define the context prediction task using a dete...\n",
            "\n",
            "Referência: BIBREF141\n",
            "  Chunk 1: ...adaptation steps in GAZP can be applied to any parser, so long as we can learn a backward utterance generator and evaluate logical-form equivalence...\n",
            "\n",
            "Referência: BIBREF1\n",
            "  Chunk 1: ...by (Gülçehre et al., 2015), who train monolingual language models independently, and then integrate them during decoding through rescoring of the b...\n",
            "\n",
            "Referência: BIBREF140\n",
            "  Chunk 1: ...abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-sh...\n",
            "\n",
            "Referência: BIBREF144\n",
            "  Chunk 1: ...measure which factors most influence end-task performance. 1 Introduction Self-supervised methods have achieved remarkable success in a wide range ...\n",
            "\n",
            "Referência: BIBREF118\n",
            "  Chunk 1: ...is also to be explored in future work. 7 Conclusion We proposed to use the Transformer model with data augmentation for the RDF-to-text task on the...\n",
            "  Chunk 2: ...study, we get our inspiration from the striking success that Transformers [29], and more specifically, a 4 A PREPRINT - DECEMBER 1, 2021 Transforme...\n",
            "\n",
            "Referência: BIBREF116\n",
            "  Chunk 1: ...and Marilyn Walker. 2018. TNT-NLG, System 1: Using a statistical NLG to massively augment crowd-sourced data for neural generation. In E2E NLG Chal...\n",
            "  Chunk 2: ...embeddings. This architecture is capable of aggregating multimodal EHR data into a single model and processing them in a temporal manner, as well a...\n",
            "\n",
            "Referência: BIBREF119\n",
            "  Chunk 1: ...from input MRs is also highly popular. In dialogue generation, Sordoni et al. (2015) propose a simple approach incorporating the previous set of re...\n",
            "  Chunk 2: ...Memory (LSTM) [25]-based language models [22]. Similar to many deep-network models, Transformer has an encoder and a decoder. The encoder converts ...\n",
            "  Chunk 3: ...and deep-learning approaches have flourished, furnishing health care providers with a new field to promote human health. Several excellent language...\n",
            "\n",
            "Referência: BIBREF120\n",
            "  Chunk 1: ...general method of data augmentation for natural language generation (NLG) problems using noise injection sampling and self- training. 2) We show a ...\n",
            "  Chunk 2: ...subwords with the GRU layer. 5.2 Robustness Analysis In this part, we further explore how the contextual word embeddings change over the character ...\n",
            "  Chunk 3: ...as a part of the embedding layer in task-specific models. GPT (Radford et al., 2019a) used the transformer decoder for language modeling by generat...\n",
            "  Chunk 4: ...dual-channel architecture for characters and original subwords and fuse them after each transformer block. Furthermore, we propose an unsupervised ...\n",
            "\n",
            "Referência: BIBREF115\n",
            "  Chunk 1: ...predict whether or not each record is used in the summary, comprising a sequence of binary classfication decision. Furthermore, they performed data...\n",
            "  Chunk 2: ...Zhao, Subendhu Rongali, Haidar Khan, and Michael Kayser. 2020. Compressing transformer-based semantic parsing models using compositional code embed...\n",
            "\n",
            "Referência: BIBREF114\n",
            "  Chunk 1: ...these challenges may be fruitfully explored, to provide a publically available dataset for this task, to suggest some automatic evaluation metrics,...\n",
            "\n",
            "Referência: BIBREF117\n",
            "  Chunk 1: Proceedings of The 10th International Natural Language Generation conference, pages 124–133, Santiago de Compostela, Spain, September 4-7 2017. c⃝2017...\n",
            "  Chunk 2: ...representations from transformers (BERT) and related models have achieved tremendous successes in the natural language processing domain. The pretr...\n",
            "\n",
            "Referência: BIBREF109\n",
            "  Chunk 1: ...tasks: Grammatical Error Correction (GEC) and Formality Style Transfer (FST). Experiments show our approach is more effective to utilize the variou...\n",
            "  Chunk 2: ...Funtowicz, and Jamie Brew. 2019. Huggingface’s transformers: State-of-the-art natural language processing. CoRR, abs/1910.03771. Shijie Wu, Alexis ...\n",
            "\n",
            "Referência: BIBREF112\n",
            "  Chunk 1: ...data augmentation methods mainly apply noise to tokens, which leads to the lack of diversity of generated errors. In view of this, we propose a new...\n",
            "\n",
            "Referência: BIBREF110\n",
            "  Chunk 1: ...to the GEC task and achieves good performance (Junczys-Dowmunt et al., 2018). Motivated by the data scarcity for the GEC task, many researchers foc...\n",
            "  Chunk 2: ...and neural network methods based on LSTMs or CNNs in many tasks, including sentence and text classification (Wang et al., 2019b). The functioning o...\n",
            "  Chunk 3: ...a setting that is relatively practical both for acquiring a few annotations (e.g., 16 examples per class) and efficiently training. 2.2 Prompt-tuni...\n",
            "  Chunk 4: ...and virtual words should be consistent with the surrounding contexts, we introduce synergistic optimization to obtain optimized virtual type and an...\n",
            "\n",
            "Referência: BIBREF66\n",
            "  Chunk 1: ...type (Ge et al., 2018a; Lichtarge et al., 2018), involving rightto-left models (Ge et al., 2018b), or by pipelining SMT and NMT-based systems (Grun...\n",
            "  Chunk 2: ...bidirectional LSTM model, applied character convolutions to its whitespace-separated input tokens. CharacterBERT (Boukkouri et al., 2020) ported th...\n",
            "  Chunk 3: ...BERT in 76 minutes. In Proc. of ICLR. Xiaodong Yu, Stephen Mayhew, Mark Sammons, and Dan Roth. 2018. On the strength of character language models f...\n",
            "\n",
            "Referência: BIBREF111\n",
            "  Chunk 1: ...are subsequently used to pre-train Transformer models. Then, by sequentially applying transfer learning, we adapt these models to the domain and st...\n",
            "  Chunk 2: ...RoBERTa (Liu et al., 2019). Social media data, however, and specifically Twitter (the platform we focus on in this paper), seem to be so far surpri...\n",
            "\n",
            "Referência: BIBREF108\n",
            "  Chunk 1: ...grammatical error correction. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–14. Asso...\n",
            "  Chunk 2: ...with open-data or test-agnostic data. In this way, the learned models behave more like humans. 5 An entailment model for 0SHOT-TC As one contributi...\n",
            "\n",
            "Referência: BIBREF113\n",
            "  Chunk 1: ...sequence models, where it has been demonstrated to have a smoothing effect on the softmax output distribution (Bowman et al., 2015; Xie et al., 201...\n",
            "  Chunk 2: ...MASS Pre-training Model Configuration We choose Transformer (Vaswani et al., 2017) as the basic model structure, which consists of 6-layer encoder ...\n",
            "  Chunk 3: ...MASS Pre-training Model Configuration We choose Transformer (Vaswani et al., 2017) as the basic model structure, which consists of 6-layer encoder ...\n",
            "  Chunk 4: ...data, our approach improves both trigger and argument detection and classification significantly over the state of the art in a zero-shot cross-lin...\n",
            "\n",
            "Referência: BIBREF133\n",
            "  Chunk 1: Proceedings of The 10th International Natural Language Generation conference, pages 198–202, Santiago de Compostela, Spain, September 4-7 2017. c⃝2017...\n",
            "  Chunk 2: ...al., 2019; Schick and Schütze, 2020; He et al., 2020) but these approaches (i) require either a customized pretraining objective or labeled trainin...\n",
            "\n",
            "Referência: BIBREF131\n",
            "  Chunk 1: ...of labeled multimodal data, we propose a Multimodal Data Augmentation (MDA) framework for boosting the performance on multimodal image-text classif...\n",
            "\n",
            "Referência: BIBREF128\n",
            "  Chunk 1: ...Data augmentation has a long history in image processing (Shorten and Khoshgoftaar, 2019). In language processing, researchers have proposed backtr...\n",
            "  Chunk 2: ...Gong, Minlong Peng, Di Liang, Keyu Ding, and Xuanjing Huang. 2018. Transferring from Formal Newswire Domain with Hypernet for Twitter POS Tagging. ...\n",
            "\n",
            "Referência: BIBREF135\n",
            "  Chunk 1: ...Data Augmentation. Compared to vision, a few efforts have been done on augmenting text for classification problems. Wei et al. [40] make a comprehe...\n",
            "  Chunk 2: ...the label, and determine if the example entails the label description. For example, we can reformulate a sentiment classification input/label pair:...\n",
            "\n",
            "Referência: BIBREF129\n",
            "  Chunk 1: ...as it only uses text data, but provides only modest improvements in performance. And while multilingual training often provides more significant im...\n",
            "  Chunk 2: ...(CT-BERT), a transformerbased model that is pre-trained on a large corpus of COVID-19 related Twitter messages. CT-BERT is specifically designed to...\n",
            "\n",
            "Referência: BIBREF130\n",
            "  Chunk 1: Multi-Modal Data Augmentation for End-to-End ASR Adithya Renduchintala, Shuoyang Ding, Matthew Wiesner, Shinji Watanabe Center for Language and Speech...\n",
            "\n",
            "Referência: BIBREF132\n",
            "  Chunk 1: ...for Image Captioning. In Proceedings of the 2019 IEEE International Conference on Computer Vision, Seoul, Korea, 27 October–2 November 2019; pp. 89...\n",
            "  Chunk 2: ...and DROP. commonsense QA datasets listed in Fig. 2. In this work, we advocate for a unifying view of QA formats by building a format-agnostic QA sy...\n",
            "  Chunk 3: ...and DROP. commonsense QA datasets listed in Fig. 2. In this work, we advocate for a unifying view of QA formats by building a format-agnostic QA sy...\n",
            "\n",
            "Referência: BIBREF134\n",
            "  Chunk 1: ...generated by our method improves IQA performance as compared to the baseline trained with the original dataset and outperforms other naive data-aug...\n",
            "  Chunk 2: ...Large pretrained language models (LMs) like GPT3 (Brown et al., 2020) have shown increasingly impressive few-shot performance by formulating tasks ...\n",
            "  Chunk 3: ...Large pretrained language models (LMs) like GPT3 (Brown et al., 2020) have shown increasingly impressive few-shot performance by formulating tasks ...\n",
            "\n",
            "Referência: BIBREF45\n",
            "  Chunk 1: ...work on data augmentation for training NLP classifiers such as Wei and Zou (2019), Lu et al. (2006), and Kobayashi (2018). We adopt some techniques...\n",
            "  Chunk 2: ...text data augmentation. There is constantly an increasing demand for large amounts of text data. Compared to fields such as computer vision, augmen...\n",
            "  Chunk 3: ...from the MIT UROP program. References Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword ...\n",
            "  Chunk 4: ...new oxford American dictionary, volume 2. Oxford University Press New York. George Miller. 1998. WordNet: An electronic lexical database. MIT press...\n",
            "\n",
            "Referência: BIBREF106\n",
            "  Chunk 1: ...synthetic data plus a much smaller but cleaner collection of text-table datasets. Data augmentation for semantic parsing Our work was inspired by e...\n",
            "  Chunk 2: ...on KATE’s performance. 6 Related Work Pre-trained Language Models NLP systems have made tremendous progress by pre-training models on unlabeled tex...\n",
            "\n",
            "Referência: BIBREF107\n",
            "  Chunk 1: ...Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 187–196. Association for Computational Linguistics. Gozde Gul Sahin and M...\n",
            "  Chunk 2: ...collecting large amounts of data is expensive. It is also important to enable a personalized Artificial Intelligence (AI) experience, where a singl...\n",
            "\n",
            "Referência: BIBREF61\n",
            "  Chunk 1: ...data augmentation. Data augmentation techniques, which generate auxiliary training data by performing structured transformation or combination of t...\n",
            "\n",
            "Referência: BIBREF24\n",
            "  Chunk 1: ...low scores is the size of the training data, i.e., training labels being too sparse to extract meaningful statistics. Label-preserving data augment...\n",
            "  Chunk 2: Data Augmentation via Dependency Tree Morphing for Low-Resource Languages G¨ozde G¨ul S¸ahin UKP Lab, Department of Computer Science Technische Univer...\n",
            "\n",
            "Referência: BIBREF105\n",
            "  Chunk 1: ...from a “shortlist” vocabulary or copy from the input, and report improvements on machine translation and text summarization. Another piece of relat...\n",
            "  Chunk 2: ...the experiments (Section 4), it is difficult to control the target language by directly fine-tuning the pre-trained translation model on downstream...\n",
            "  Chunk 3: ...with prior state-of-the-art fine-tuning approaches. Prompt Design for PLMs The core challenge of prompt design is to convert training data (if it e...\n",
            "\n",
            "Referência: BIBREF67\n",
            "  Chunk 1: ...and machine translation, and are by now standard tools for sequential natural language tasks (e.g., Mikolov et al., 2010; Graves, 2012; Wu et al., ...\n",
            "  Chunk 2: ...language out of the box, they are more robust to noise, and they minimize technical debt by removing complex and error-prone text preprocessing pip...\n",
            "  Chunk 3: ...a few recent efforts to develop general-purpose token-free pre-trained language models for transfer learning.2 Akbik et al. (2018) show strong resu...\n",
            "\n",
            "Referência: BIBREF102\n",
            "  Chunk 1: Logic-Guided Data Augmentation and Regularization for Consistent Question Answering Akari Asai† and Hannaneh Hajishirzi†‡ †University of Washington ‡A...\n",
            "\n",
            "Referência: BIBREF100\n",
            "  Chunk 1: arXiv:1904.06652v1 [cs.CL] 14 Apr 2019 Data Augmentation for BERT Fine-Tuning in Open-Domain Question Answering Wei Yang,1,2∗ Yuqing Xie,1,2∗ Luchen T...\n",
            "  Chunk 2: Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models Robert L. Logan IV1 Ivana Balaževi´c∗2 Eric Wallace3 Fabio Petro...\n",
            "  Chunk 3: ...2020. AutoPrompt: Eliciting knowledge from language models with automatically generated prompts. In EMNLP. Alex Wang, Yada Pruksachatkun, Nikita Na...\n",
            "\n",
            "Referência: BIBREF68\n",
            "  Chunk 1: XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering Jasdeep Singh1, Bryan McCann2, Nitish Shirish Keskar2, Cai...\n",
            "  Chunk 2: ...Via extensive experiments on English GLUE, multilingual, and noisy text datasets, we show that CHARFORMER outperforms a series of competitive byte-...\n",
            "  Chunk 3: ...1391– 1399, Republic and Canton of Geneva, CHE, 2017. International World Wide Web Conferences Steering Committee. ISBN 9781450349130. doi: 10.1145...\n",
            "\n",
            "Referência: BIBREF101\n",
            "  Chunk 1: ...to the corresponding English ones. Question Generation for Question Answering Data augmentation via synthetic data generation is a well-known techn...\n",
            "\n",
            "Referência: BIBREF99\n",
            "  Chunk 1: An Exploration of Data Augmentation and Sampling Techniques for Domain-Agnostic Question Answering Shayne Longpre∗, Yi Lu∗, Zhucheng Tu∗, Chris DuBois...\n",
            "  Chunk 2: ...Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowledge bases? In Proceedings of EMNLP, pages 2463–2473....\n",
            "  Chunk 3: ...(2021) first explore automatic identification of label words for human-picked templates. Shin et al. (2020) further explore gradientguided search t...\n",
            "\n",
            "Referência: BIBREF103\n",
            "  Chunk 1: ...and answers in the dataset as well. In addition, we can combine this method with other data augmentation methods, such as, the type swap method (Ra...\n",
            "  Chunk 2: ...classification objective and does not scale to long output sequences. Radford et al. (2019) consider task descriptions for text generation tasks, b...\n",
            "\n",
            "Referência: BIBREF65\n",
            "  Chunk 1: ...pre-trained language models are also used in some NLP tasks (Kobayashi, 2018; Wei and Zou, 2019; Anaby-Tavor et al., 2020; Raille et al., 2020; Kum...\n",
            "  Chunk 2: ...to misspellings as evidenced by the slower decrease in performance compared to BERT. In particular, when a noise level of 40% is applied to the tes...\n",
            "  Chunk 3: ...despite it not being intrinsically linked to the notion of Transformers. While this system is thought to achieve a good balance between the flexibi...\n",
            "  Chunk 4: ...despite it not being intrinsically linked to the notion of Transformers. While this system is thought to achieve a good balance between the flexibi...\n",
            "\n",
            "Referência: BIBREF69\n",
            "  Chunk 1: ...Craven. 2008. An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the 2008 Conference on Empirical Methods in ...\n",
            "  Chunk 2: ...for nlp. arXiv preprint arXiv:2104.06387, 2021. [39] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-t...\n",
            "  Chunk 3: ...for nlp. arXiv preprint arXiv:2104.06387, 2021. [39] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-t...\n",
            "  Chunk 4: ...for nlp. arXiv preprint arXiv:2104.06387, 2021. [39] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-t...\n",
            "\n",
            "Referência: BIBREF27\n",
            "  Chunk 1: ...the original CNN (Kim 2014) (denoted as CNNsen), and three recent text augmentation methods including EDA (Wei and Zou 2019), wordMixup and senMixu...\n",
            "  Chunk 2: ...short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-ofthe-art res...\n",
            "\n",
            "Referência: BIBREF35\n",
            "  Chunk 1: Sequence-Level Mixed Sample Data Augmentation Demi Guo Harvard University dguo@college.harvard.edu Yoon Kim MIT-IBM Watson AI Lab yoonkim@ibm.com Alex...\n",
            "  Chunk 2: ...al., 2018; Radford et al., 2018; Devlin et al., 2018; Yang et al., 2019; Liu et al., 2019; Raffel et al., 2019) have brought dramatic empirical imp...\n",
            "\n",
            "Referência: BIBREF32\n",
            "  Chunk 1: ...images and combining image labels as virtual training data and have achieved state-ofthe-art performances across a variety of tasks like image clas...\n",
            "\n",
            "Referência: BIBREF36\n",
            "  Chunk 1: ...Amodei et al., 2016). In image processing, simple augmentation techniques such as flipping, cropping, or increasing and decreasing the contrast of ...\n",
            "  Chunk 2: ...categories of pre-trained models. First, the encoder-only models (e.g., RoBERTa, CodeBERT, and GraphCodeBERT) that are combined with a randomly ini...\n",
            "  Chunk 3: ...use, including the linguistic features and word embeddings, are provided by the shared task organizer (Hershcovich et al., 2019). We also adopt the...\n",
            "\n",
            "Referência: BIBREF33\n",
            "  Chunk 1: ...time stretching, pitch shifting, dynamic range compression, and adding background noise chosen from an external dataset. One major disadvantage of ...\n",
            "  Chunk 2: ...Table 11 shows which of the strategies for continued pretraining have already been explored in the prior work from the Related Work (§6). As eviden...\n",
            "  Chunk 3: ...on human-curated datasets, and a simple data selection strategy to automatically approach this performance. Our code as well as pretrained models f...\n",
            "  Chunk 4: ...on human-curated datasets, and a simple data selection strategy to automatically approach this performance. Our code as well as pretrained models f...\n",
            "  Chunk 5: ...{first-name}@huggingface.co Abstract Recent progress in natural language processing has been driven by advances in both model architecture and mode...\n",
            "\n",
            "Referência: BIBREF26\n",
            "  Chunk 1: ...al. 2014b) addresses this issue by dropping the entire feature map from a convolutional layer. DropBlock (Ghiasi, Lin, and Le 2018) further improve...\n",
            "  Chunk 2: ...featured a trend towards pre-trained language representations in NLP systems, applied in increasingly flexible and task-agnostic ways for downstrea...\n",
            "  Chunk 3: ...featured a trend towards pre-trained language representations in NLP systems, applied in increasingly flexible and task-agnostic ways for downstrea...\n",
            "  Chunk 4: ...featured a trend towards pre-trained language representations in NLP systems, applied in increasingly flexible and task-agnostic ways for downstrea...\n",
            "  Chunk 5: ...featured a trend towards pre-trained language representations in NLP systems, applied in increasingly flexible and task-agnostic ways for downstrea...\n",
            "  Chunk 6: ...(Mikolov et al., 2013; Pennington et al., 2014) or contextualized (McCann et al., 2017; Peters et al., 2018), to full-network pre-training followed...\n",
            "\n",
            "Referência: BIBREF4\n",
            "  Chunk 1: ...baseline. We report the median test errors of the last 10 epochs. Results are shown in Table 5. From the ablation study experiments, we have the fo...\n",
            "  Chunk 2: ...Pre-training Masked Language Model Pre-training 0 1 2 3 4 Pre-train FLOPs 1e21 70 75 80 85 90 RoBERTa 300k steps RoBERTa 500k steps XLNet Figure 1:...\n",
            "  Chunk 3: ...al., 2015). McCann et al. (2017) explored the use of representations derived from machine translation models and Howard & Ruder (2018) improved the...\n",
            "\n",
            "Referência: BIBREF31\n",
            "  Chunk 1: ...of options when utilizing this data augmentation method allows for lots of exploration on how to use the technique most effectively. Prior work [12...\n",
            "  Chunk 2: ...In Proceedings of the First Workshop on Subword and Character Level Models in NLP, pages 97–102. Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, N...\n",
            "\n",
            "Referência: BIBREF34\n",
            "  Chunk 1: ...to describe the space of adversarial examples centered around each training example. Unlike prior work (Cheng et al., 2019), we first generate adve...\n",
            "  Chunk 2: ...GPT-2 [59], which consists of 12 layers of Transformer decoders. More model settings are listed in Table 4. We pretrain monolingual models on Pytho...\n",
            "  Chunk 3: ...from a severe inefficiency issue. This work is built on the high-performance modern neural parser based on a BiLSTM encoder [Stern et al., 2017], w...\n",
            "\n",
            "Referência: BIBREF30\n",
            "  Chunk 1: ...a more aggressive approach with image augmentation when training Deep Image [21] on the ImageNet dataset. In addition to flipping and cropping they...\n",
            "  Chunk 2: ...pre-training of language models on large corpora, such as BERT (Devlin et al., 2019), ELMo (Peters et al., 2018), ULM-Fit (Howard and Ruder, 2018),...\n",
            "\n",
            "Referência: BIBREF11\n",
            "  Chunk 1: ...prior text augmentation methods. Through human evaluations (N=178), we confirm that Data Boost augmentation has comparable quality as the original ...\n",
            "  Chunk 2: ...large target network without overfitting; Recent studies have taken advantage of this fact to obtain state-of-the-art results when transferring fro...\n",
            "\n",
            "Referência: BIBREF51\n",
            "  Chunk 1: ...Barcelona, Spain (Online): International Committee on Computational Linguistics. Feng, S. Y.; Gangal, V.; Kang, D.; Mitamura, T.; and Hovy, E. 2020...\n",
            "  Chunk 2: ...Barrault, and Antoine Bordes. 2017. Supervised learning of universal sentence representations from natural language inference data. arXiv preprint ...\n",
            "  Chunk 3: ...specific problem. They suggest fine-tuning pre-trained bidirectional transformers for specific problems. Radford et al. (Radford et al.) introduced...\n",
            "\n",
            "Referência: BIBREF42\n",
            "  Chunk 1: ...NLI tasks, we compare against 3 data augmentation methods. Easy Data Augmentation (EDA) (Wei and Zou, 2019) is a heuristic method that randomly rep...\n",
            "  Chunk 2: ...is available at https://github.com/bert-nmt/bert-nmt. 1 INTRODUCTION Recently, pre-training techniques, like ELMo (Peters et al., 2018), GPT/GPT-2 ...\n",
            "  Chunk 3: ...is available at https://github.com/bert-nmt/bert-nmt. 1 INTRODUCTION Recently, pre-training techniques, like ELMo (Peters et al., 2018), GPT/GPT-2 ...\n",
            "\n",
            "Referência: BIBREF55\n",
            "  Chunk 1: ...for specific manipulation schemes: (1) For text data augmentation, we compare with the latest model-based augmentation [49] which uses a fixed cond...\n",
            "  Chunk 2: ...evaluation scripts. The main evaluation is the average F1 of the three metrics. Results on the test set are shown in Table 1. We include performanc...\n",
            "\n",
            "Referência: BIBREF48\n",
            "  Chunk 1: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 7400–7410, November 16–20, 2020. c⃝2020 Association for ...\n",
            "  Chunk 2: 1 Self-supervised Learning: Generative or Contrastive Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, Jie Tang*, IEEE Fellow Abs...\n",
            "  Chunk 3: ...responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveal...\n",
            "\n",
            "Referência: BIBREF46\n",
            "  Chunk 1: ...2019), proposes fine-tuned BERT (Devlin et al. 2019) for data augmentation by carrying out a masked prediction of words, while conditioning on the ...\n",
            "  Chunk 2: 1 Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing YU GU∗, ROBERT TINN∗, HAO CHENG∗, MICHAEL LUCAS, NAOTO USUYAMA...\n",
            "  Chunk 3: ...data sparsity, which makes it difficult to represent large contexts and thus, long-range dependencies. Neural language models tackle this issue by ...\n",
            "\n",
            "Referência: BIBREF57\n",
            "  Chunk 1: ...transformations, in fixed order or at random, and with parameters drawn randomly from hand-tuned ranges. In addition, various studies have applied ...\n",
            "  Chunk 2: ...interact and the shared parameters are frozen. This means that the model has perfect memory of previous tasks using a small number of task-specific...\n",
            "\n",
            "Referência: BIBREF59\n",
            "  Chunk 1: ...Zaidan & Eisner, 2008; Poulis & Dasgupta, 2017). To combat gender stereotypes, Lu et al. (2018); Zmigrod et al. (2019); Maudslay et al. (2019) desc...\n",
            "\n",
            "Referência: BIBREF2\n",
            "  Chunk 1: ...time. Our approach of learning data augmentation policies from data in principle can be used for any dataset, not just one. This paper introduces a...\n",
            "\n",
            "Referência: BIBREF151\n",
            "  Chunk 1: ...model distribution on given samples. The proposed measure, coined the gap of log-densities (GOLD), provides an effective self-diagnosis for cGANs w...\n",
            "\n",
            "Referência: BIBREF152\n",
            "  Chunk 1: ...realistic samples for complex generation tasks, including image/video synthesis [6, 27], style transfer [55, 16], and data augmentation [36]. Howev...\n",
            "\n",
            "Referência: BIBREF287\n",
            "  Chunk 1: ...Instead of changing the Transformer attention mechanism, we propose to improve absolute sinusoidal positional encodings in two ways: a) instead of ...\n",
            "\n",
            "Referência: BIBREF233\n",
            "  Chunk 1: ...the initialization distribution. Howard & Ruder, 2018; Radford et al., 2018) In NLP, the upstream model is usually a neural language model (Bengio ...\n",
            "\n",
            "Referência: BIBREF219\n",
            "  Chunk 1: ...second part, we leverage the transfer results from part one to automatically rank and identify beneficial intermediate tasks. With the rise of larg...\n",
            "  Chunk 2: What to Pre-Train on? Efficient Intermediate Task Selection Clifton Poth, Jonas Pfeiffer, Andreas Rücklé∗, and Iryna Gurevych Ubiquitous Knowledge Pro...\n",
            "\n",
            "Referência: BIBREF241\n",
            "  Chunk 1: ...show that our method outperforms vanilla fine-tuning by up to 30% (and 11% on average). We concluded by discussing the limitations of our approach,...\n",
            "  Chunk 2: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Languag...\n",
            "  Chunk 3: ...covering 36% of the total, and the top 1,000 covering 69%. 5 Model To set initial performance levels on AMBIGNQ, we present a baseline AMBIGQA mode...\n",
            "\n",
            "Referência: BIBREF245\n",
            "  Chunk 1: ...computed by the Transformer. 3.3 Fine-tuning In the full fine-tuning framework, we initialize with the pretrained parameters φ. Here pφ is a traina...\n",
            "  Chunk 2: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Languag...\n",
            "  Chunk 3: COINS: Dynamically Generating COntextualized Inference Rules for Narrative Story Completion Debjit Paul Research Training Group AIPHES Institute for C...\n",
            "\n",
            "Referência: BIBREF243\n",
            "  Chunk 1: ...pretrained models in the HuggingFace transformers library (Wolf et al., 2019) on arbitrary datasets. 3 Sentiment Analysis Sentiment analysis is a f...\n",
            "  Chunk 2: ...pretrained models in the HuggingFace transformers library (Wolf et al., 2019) on arbitrary datasets. 3 Sentiment Analysis Sentiment analysis is a f...\n",
            "  Chunk 3: ...Proceedings of the 2008 ACM SIGMOD international conference on Management of data. AcM, pages 1247–1250. Antoine Bordes, Nicolas Usunier, Sumit Cho...\n",
            "\n",
            "Referência: BIBREF165\n",
            "  Chunk 1: ...up to 98% of their original performance. We also show that our pruned models are on par with DistilBERT in terms of both model size and performance...\n",
            "  Chunk 2: ...up to 98% of their original performance. We also show that our pruned models are on par with DistilBERT in terms of both model size and performance...\n",
            "  Chunk 3: ...al., 2020) that shows the ability of these huge pre-trained Language Models to solve tasks for which have not even trained. Recently, with the arri...\n",
            "\n",
            "Referência: BIBREF247\n",
            "  Chunk 1: ...multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang...\n",
            "  Chunk 2: ...show strong results on generative tasks. This method freezes the model parameters and backpropagates the error during tuning to prefix activations ...\n",
            "  Chunk 3: ...which an inference is strengthened or weakened. From the collected data, we formulate a classification task and a generation task for defeasible in...\n",
            "\n",
            "Referência: BIBREF161\n",
            "  Chunk 1: Compression of Deep Learning Models for Text: A Survey MANISH GUPTA and PUNEET AGRAWAL, Microsoft, India In recent years, the fields of natural langua...\n",
            "  Chunk 2: Compression of Deep Learning Models for Text: A Survey MANISH GUPTA and PUNEET AGRAWAL, Microsoft, India In recent years, the fields of natural langua...\n",
            "\n",
            "Referência: BIBREF289\n",
            "  Chunk 1: ...memory efficiency of several Transformer variants and their underlying self-attention mechanisms in detail. As introduced earlier, the BERT model a...\n",
            "\n",
            "Referência: BIBREF159\n",
            "  Chunk 1: ...et al., 2020), mT5 (Xue et al., 2021), and InfoXLM (Chi et al., 2021) as future work. Note that the above ML-LMs are pretrained only with token-lev...\n",
            "  Chunk 2: ...Computational Linguistics. Alexis Conneau and Guillaume Lample. 2019. Crosslingual language model pretraining. In Advances in Neural Information Pr...\n",
            "  Chunk 3: ...Computational Linguistics. Alexis Conneau and Guillaume Lample. 2019. Crosslingual language model pretraining. In Advances in Neural Information Pr...\n",
            "\n",
            "Referência: BIBREF156\n",
            "  Chunk 1: ...of Transformers for Language Understanding Among the recent works for pretraining language representation models, most of them are based on the Tra...\n",
            "  Chunk 2: ...etc. have achieved dominating performance in various natural language processing tasks, such as text generation, reading comprehension, text classi...\n",
            "\n",
            "Referência: BIBREF54\n",
            "  Chunk 1: ...that learning to detect shuffled tokens is a promising approach to learn more coherent sentence representations.1 1 Introduction The method of pre-...\n",
            "  Chunk 2: ...that learning to detect shuffled tokens is a promising approach to learn more coherent sentence representations.1 1 Introduction The method of pre-...\n",
            "  Chunk 3: ...not appear to have any adverse effects. 7 Related Work Pre-trained contextualized word representations that can be trained from unlabeled text (Dai...\n",
            "\n",
            "Referência: BIBREF299\n",
            "  Chunk 1: ...in pretrained LMs. As a step towards mitigating bias in LMs, our second contribution is a new method called AUTOREGRESSIVE INLP (A-INLP) that is ab...\n",
            "\n",
            "Referência: BIBREF181\n",
            "  Chunk 1: ...bias from gender-neutral terms [40]. Vig et al. investigate which model components (attention heads) are responsible for gender bias in transformer...\n",
            "  Chunk 2: ...J. Reagan, and C. M. Danforth. Allotaxonometry and rank-turbulence divergence: A universal instrument for comparing complex systems. arXiv preprint...\n",
            "  Chunk 3: ...[2, 24, 27]. The idea is to train a language model on a large amount of text using a next word prediction objective to learn good representations f...\n",
            "\n",
            "Referência: BIBREF297\n",
            "  Chunk 1: ...machine (SVM), random forest, and Bayes) and deep learning algorithms (e.g., Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Hi...\n",
            "\n",
            "Referência: BIBREF298\n",
            "  Chunk 1: ...which takes the pooled last hidden states as input. ULMFit comes with novel training strategies for further pretraining the language model on domai...\n",
            "\n",
            "Referência: BIBREF77\n",
            "  Chunk 1: ...Wang, Pan Zhou, and Tao Zhang. 2017. A survey of model compression and acceleration for deep neural networks. arXiv preprint arXiv:1710.09282. Nige...\n",
            "  Chunk 2: ...dataset. vector of ‘lymphoma’ is initialized by the average embedding vector of ‘lym’, ‘##pho’and ‘##ma’. 3. After model initialization and data pr...\n",
            "\n",
            "Referência: BIBREF184\n",
            "  Chunk 1: ...Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. Rezarta Islamaj Do˘gan, Robert Leaman,...\n",
            "  Chunk 2: ...Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. Rezarta Islamaj Do˘gan, Robert Leaman,...\n",
            "\n",
            "Referência: BIBREF183\n",
            "  Chunk 1: ...is expensive, environmentally unfriendly, prohibitive for small research labs and students, and may delay prototyping on emerging domains. We there...\n",
            "  Chunk 2: ...-ia diseases. To combine these complementary strengths, we use a 50/50 mixture of TLM-tokenization and ˆTLMtokenization when finetuning the PTLM on...\n",
            "\n",
            "Referência: BIBREF47\n",
            "  Chunk 1: ...Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive language models beyond a fixed-length context. arXiv preprint arXiv:1901.02860. Jacob Devlin,...\n",
            "  Chunk 2: ...Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. ...\n",
            "\n",
            "Referência: BIBREF44\n",
            "  Chunk 1: ...Bert: pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chap...\n",
            "  Chunk 2: ...al., 2016; McCann et al., 2017; Peters et al., 2018; Devlin et al., 2019) have been shown to improve downstream NLP tasks. Pre-trained contextualiz...\n",
            "\n",
            "Referência: BIBREF292\n",
            "  Chunk 1: ...Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the Nor...\n",
            "\n",
            "Referência: BIBREF293\n",
            "  Chunk 1: ...W. Liu, B. P. S. Rawat, P. Cai, and H. Yu. 2019. Fine-Tuning Bidirectional Encoder Representations From Transformers (BERT)-Based Models on Large-S...\n",
            "\n",
            "Referência: BIBREF296\n",
            "  Chunk 1: ...Nicholas Carlini, Chang Liu, Jernej Kos, Úlfar Erlingsson, and Dawn Xiaodong Song. 2018. The secret sharer: Measuring unintended neural network mem...\n",
            "\n",
            "Referência: BIBREF295\n",
            "  Chunk 1: ...the competitor’s private message corpus. Various methods have been proposed to measure the degree to which an adversary can achieve this (Carlini e...\n",
            "\n",
            "Referência: BIBREF294\n",
            "  Chunk 1: ...e.g., dialogue 12 systems [76] and summarization models [29], LMs are finetuned on task-specific data. On the positive side, this finetuning proces...\n",
            "\n",
            "Referência: BIBREF290\n",
            "  Chunk 1: ...show the different sensitivities to different types of words, and suggest the necessity of considering the robustness of the neural models. We will...\n",
            "\n",
            "Referência: BIBREF291\n",
            "  Chunk 1: ...for our work on robust deep learning under distribution shift. References Yonatan Belinkov and Yonatan Bisk. 2018. Synthetic and natural noise both...\n",
            "\n",
            "Referência: BIBREF218\n",
            "  Chunk 1: ...procedure of fine-tuning a pretrained model on a target task, as described in Devlin et al. (2019). We opt for single intermediate-task training as...\n",
            "\n",
            "Referência: BIBREF230\n",
            "  Chunk 1: ...with BERT-style models. Intermediate Training Given the robust success of LM pretraining, we explore methods of further improving on such sentence ...\n",
            "  Chunk 2: ...with the model’s internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following questio...\n",
            "\n",
            "Referência: BIBREF213\n",
            "  Chunk 1: ...2018), and a variant of ELMo (Peters et al., 2018a). We follow Radford et al. and Devlin et al. in our basic mechanism for finetuning both for the ...\n",
            "  Chunk 2: ...generated synthetic data is a long standing research goal (Mitkov and Ha, 2003; Rus et al., 2010). Although many past works have proposed different...\n",
            "\n",
            "Referência: BIBREF226\n",
            "  Chunk 1: ...intermediate model was further fine-tuned using the STS-Clinic corpus in phase 2. The fine-tuned model from the second phase was used for final tes...\n",
            "\n",
            "Referência: BIBREF224\n",
            "  Chunk 1: ...skip the intermediate finetune and directly train BERT on our 2 Figure 1: We perform a double finetune from BERT to an intermediate task to our med...\n",
            "  Chunk 2: ...However, it is also important to be able to justify the decisions that were made and explain why they are reasonable in a human understandable mann...\n",
            "\n",
            "Referência: BIBREF229\n",
            "  Chunk 1: ...for intermediate finetuning improves performance [2, 20, 36]. Therefore, we evaluated our proposed method of fine-tuning BioBERT using the sequence...\n",
            "  Chunk 2: arXiv:1812.01193v2 [cs.CL] 6 Dec 2018 e-SNLI: Natural Language Inference with Natural Language Explanations Oana-Maria Camburu1 Tim Rocktäschel2 Thoma...\n",
            "\n",
            "Referência: BIBREF225\n",
            "  Chunk 1: ...(2017) proposed the Transformer as an alternative model to the RNN. Since the Transformer is based on a self-attention mechanism rather than recurr...\n",
            "  Chunk 2: ...encoder-decoder paradigm (Sutskever et al., 2014; Bahdanau et al., 2014; Kalchbrenner and Blunsom, 2013), and inherits ideas from the extensive lit...\n",
            "\n",
            "Referência: BIBREF227\n",
            "  Chunk 1: ...Moreover, based on the results for CLS-BERTbase and HConvBERTbase using STS-PL and STS-PS, it would appear that the amount and score distribution o...\n",
            "  Chunk 2: ...issue is faced when automating explanations of decisions: the generated explanations are generic, and designed to be useful to the recipient of the...\n",
            "\n",
            "Referência: BIBREF228\n",
            "  Chunk 1: ...Question Answering · Pre-trained Language Model · Transfer Learning 1 Introduction Language models pre-trained on large-scale text corpora achieve ...\n",
            "\n",
            "Referência: BIBREF223\n",
            "  Chunk 1: ...use of MTL with transformer-based models (BERT) on multiple biomedical and clinical NLP tasks. We hypothesize the performance of the models on indi...\n",
            "  Chunk 2: Multimodal Explanations: Justifying Decisions and Pointing to the Evidence Dong Huk Park1, Lisa Anne Hendricks1, Zeynep Akata2,3, Anna Rohrbach1,3, Be...\n",
            "\n",
            "Referência: BIBREF221\n",
            "  Chunk 1: ...the greatest relative reduction in multitasking performance occurs on datasets (MedNLI, MedRQE and quaero-2014) with orthogonal characteristics to ...\n",
            "\n",
            "Referência: BIBREF222\n",
            "  Chunk 1: ...to the task-specific objective for task t. We used the mini-batch–based stochastic gradient descent to update the parameters. A detailed explanatio...\n",
            "\n",
            "Referência: BIBREF232\n",
            "  Chunk 1: ...lack of extensive training data. Basic premise behind multi-task learning is that different datasets may have semantic and syntactic similarities a...\n",
            "\n",
            "Referência: BIBREF231\n",
            "  Chunk 1: ...task-specific fine-tuning. 7.3 GPT/GPT-2 BERT is not the only type of language model that has successfully performed in MTL environments. GPT (Radf...\n",
            "  Chunk 2: ...these models have been proved to improve the decision-making performance. Therefore, providing faithful textual explanations has become a promising...\n",
            "\n",
            "Referência: BIBREF220\n",
            "  Chunk 1: ...based on their relevance scores computed using Equation 5. 3.1 The Training Procedure The training procedure of MT-DNN consists of two stages: pret...\n",
            "  Chunk 2: ...a model. 2. THE CASE FOR EXPLANATIONS By“explaining a prediction”, we mean presenting textual or visual artifacts that provide qualitative understa...\n",
            "\n",
            "Referência: BIBREF246\n",
            "  Chunk 1: ...gap between GPTs and NLU applications.1 Ptuning leverages few continuous free parameters to serve as prompts fed as the input to the pre-trained la...\n",
            "  Chunk 2: ...We train a model that can learn from the NLP task and effectively transfer it to generate inference graphs. Such transfer learning is made possible...\n",
            "\n",
            "Referência: BIBREF238\n",
            "  Chunk 1: ...Learning how to ask: Querying LMs with mixtures of soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of the Associa...\n",
            "  Chunk 2: ...may be viewed as a starting tool for modeling a stratiform theory of natural language pro- cessing. VII. CONCLUSION Knowledge-based report generati...\n",
            "\n",
            "Referência: BIBREF240\n",
            "  Chunk 1: ...in Figure 5 Prompts Top1 Top3 Top5 Opti. Oracle before 31.9 34.5 33.8 38.1 47.9 after 30.2 32.5 34.7 37.5 50.8 Table 14: Micro-averaged accuracy (%...\n",
            "  Chunk 2: ...requires generating a disambiguated question for each of the plausible answers. They propose SPANSEQGEN, which first retrieves and reranks arXiv:20...\n",
            "\n",
            "Referência: BIBREF239\n",
            "  Chunk 1: ...excel for the former but only provide small improvements for tasks that fall into the latter category. While this provides insights into the lingui...\n",
            "  Chunk 2: ...and Ruslan Salakhutdinov. 2019. Transformer-xl: Attentive language models beyond a fixed-length context. CoRR, abs/1901.02860. Yann N. Dauphin, Ang...\n",
            "  Chunk 3: ...and William Yang Wang. 2020. Kgpt: Knowledge-grounded pretraining for data-to-text generation. arXiv preprint arXiv:2010.02307. Ryan Clancy, Ihab F...\n",
            "\n",
            "Referência: BIBREF242\n",
            "  Chunk 1: ...for nlp. arXiv preprint arXiv:2104.06387, 2021. [39] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-t...\n",
            "  Chunk 2: ...and Zhai, 2010) in that they both expand the queries with relevant contexts (terms) without the use of external supervision. GAR is superior as it ...\n",
            "\n",
            "Referência: BIBREF258\n",
            "  Chunk 1: ...produced by ESPnet (Watanabe et al., 2018) on LibriSpeech’s dev and test sets. The ESPnet model was the sequence-to-sequence BLSTMP model in the li...\n",
            "  Chunk 2: ...to directed and labeled relations between observable, lexical units of the linguistic signal. Second, our work is grounded in the practical goal of...\n",
            "\n",
            "Referência: BIBREF253\n",
            "  Chunk 1: ...NLP systems. Peters et al. (2018a) introduced LSTMbased deep contextual representations and obtained large performance gains by fine-tuning on task...\n",
            "  Chunk 2: ...of NLP tasks, lots of works study to what extent pre-trained models inherently. Here, we will introduce recent works on probing linguistic informat...\n",
            "\n",
            "Referência: BIBREF256\n",
            "  Chunk 1: ...Funtowicz, and Jamie Brew. 2019. Huggingface’s transformers: State-of-the-art natural language processing. CoRR, abs/1910.03771. Shijie Wu, Alexis ...\n",
            "  Chunk 2: ...of those well pre-trained language models, we argue that current techniques which only focus on language modeling restrict the power of the pretrai...\n",
            "\n",
            "Referência: BIBREF185\n",
            "  Chunk 1: ...schema and memory networks. In ACL, pages 358–365, Vancouver, Canada. Joe Davison, Joshua Feldman, and Alexander M Rush. 2019. Commonsense knowledg...\n",
            "  Chunk 2: ...schema and memory networks. In ACL, pages 358–365, Vancouver, Canada. Joe Davison, Joshua Feldman, and Alexander M Rush. 2019. Commonsense knowledg...\n",
            "  Chunk 3: ...schema and memory networks. In ACL, pages 358–365, Vancouver, Canada. Joe Davison, Joshua Feldman, and Alexander M Rush. 2019. Commonsense knowledg...\n",
            "\n",
            "Referência: BIBREF252\n",
            "  Chunk 1: ...sources: (i) GoogleRE. 3 relations: “place of birth”, “date of birth”, “place of death”. (ii) T-REx (Elsahar et al., 2018). Subset of Wikidata trip...\n",
            "\n",
            "Referência: BIBREF251\n",
            "  Chunk 1: ...Wei, Xuanjing Huang, Jianshu Ji, Guihong Cao, Daxin Jiang, and Ming Zhou. 2020. K-adapter: Infusing knowledge into pre-trained models with adapters...\n",
            "\n",
            "Referência: BIBREF255\n",
            "  Chunk 1: ...using a Transformer architecture and a masked language modeling task. There are roughly two types of approaches for explicitly learning high-qualit...\n",
            "  Chunk 2: ...in transformers for SRL (Strubell et al., 2018). In parallel, there has been a renewed interest in investigating self-supervised learning approache...\n",
            "\n",
            "Referência: BIBREF23\n",
            "  Chunk 1: . Invited Review. Pre-trained Models for Natural Language Processing: A Survey Xipeng Qiu*, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai & Xuanjing H...\n",
            "\n",
            "Referência: BIBREF53\n",
            "  Chunk 1: ...to be discovered. The rapid development of transformer-based models on a variety of NLP-related tasks demonstrates its structural superiority and v...\n",
            "  Chunk 2: ...indicates that, compared to ELMo and BERT-base, BERT-large is particularly better at distinguishing between related but distinct entities (e.g., Pr...\n",
            "\n",
            "Referência: BIBREF52\n",
            "  Chunk 1: ...on ImageNet train set as compared to the case when pretrained on JFT dataset [47] with 300 million images. Since acquiring manual labels at a massi...\n",
            "  Chunk 2: ...Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficien...\n",
            "\n",
            "Referência: BIBREF49\n",
            "  Chunk 1: ...in humans: infants learn language by listening to adults around them - a process that requires learning good representations of speech. In machine ...\n",
            "  Chunk 2: ...Introduction Large pre-trained language models achieve very high accuracy when fine-tuned on supervised tasks (Dai and Le, 2015; Peters et al., 201...\n",
            "\n",
            "Referência: BIBREF50\n",
            "  Chunk 1: ...obvious that the transfer learning framework will benefit from more speech signals of the test user, our goal is to achieve the best possible perso...\n",
            "  Chunk 2: ...al., 2019) and T5 (Raffel et al., 2019). It has been shown that language modeling pretraining significantly improves the performance of many natura...\n",
            "\n",
            "Referência: BIBREF122\n",
            "  Chunk 1: ...notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that t...\n",
            "  Chunk 2: ...particular, we significantly raise the state-of-the-art (88.33 F1, ↑9.56 pp vs. Lample et al. (2016)). We hypothesize that pre-trained contextual c...\n",
            "\n",
            "Referência: BIBREF121\n",
            "  Chunk 1: ...fix the weights and add additional taskspecific model capacity, allowing us to leverage large, rich and universal biLM representations for cases wh...\n",
            "  Chunk 2: ...inductive bias on the ELMo weights to stay close to an average of all biLM layers. 3.4 Pre-trained bidirectional language model architecture The pr...\n",
            "\n",
            "Referência: BIBREF60\n",
            "  Chunk 1: ...1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still ...\n",
            "  Chunk 2: ...Transformer (Vaswani et al., 2017) based architecture for our LMs. The model largely follows the details of the OpenAI GPT model (Radford et al., 2...\n",
            "  Chunk 3: ...1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still ...\n",
            "\n",
            "Referência: BIBREF125\n",
            "  Chunk 1: ...intelligence research, 16:321–357. Sheng Chen, Haibo He, and Edwardo A Garcia. 2010. Ramoboost: ranked minority oversampling in boosting. IEEE Tran...\n",
            "\n",
            "Referência: BIBREF39\n",
            "  Chunk 1: ...attention, such as UniLM (Dong et al., 2019). Conditional language model pre-training is also proposed. For example, CTRL (Keskar et al., 2019) is ...\n",
            "  Chunk 2: ...attention, such as UniLM (Dong et al., 2019). Conditional language model pre-training is also proposed. For example, CTRL (Keskar et al., 2019) is ...\n",
            "  Chunk 3: ...Contextualized Vectors Recent work has shown that the use of pretrained networks improves the performance of downstream tasks. BO uses pre-trained ...\n",
            "\n",
            "Referência: BIBREF73\n",
            "  Chunk 1: ...substantially reduces training time. Pre-trained models for the Russian language are open sourced. 1 Introduction A large amount of work is devoted...\n",
            "\n",
            "Referência: BIBREF62\n",
            "  Chunk 1: ...compare these three approaches on three different metrics: cosine similarity, L2 distance and cross-lingual word similarity. 5 Experiments and resu...\n",
            "  Chunk 2: ...38.5 BLEU on WMT’16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made pub...\n",
            "\n",
            "Referência: BIBREF40\n",
            "  Chunk 1: ...arXiv preprint arXiv:1607.06450, 2016. Jay Alammar. The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning). Retrieved from http://...\n",
            "  Chunk 2: ...Pre-training Data 4.2.1 Data Collection The domain-specific corpus was collected by scraping all the text content from wwwin.cisco.com, the Cisco c...\n",
            "  Chunk 3: ...tasks to combinatorially constrained hidden syntactic representations. Bowman et al. (2016); Yogatama et al. (2017) and Choi et al. (2018) generate...\n",
            "\n",
            "Referência: BIBREF63\n",
            "  Chunk 1: ...effects of training unsupervised crosslingual representations at a very large scale. We present XLM-R a transformer-based multilingual masked langu...\n",
            "  Chunk 2: ...effects of training unsupervised crosslingual representations at a very large scale. We present XLM-R a transformer-based multilingual masked langu...\n",
            "\n",
            "Referência: BIBREF72\n",
            "  Chunk 1: ...and the Lorentz transformations. Based on the fully hyperbolic framework, we successfully train a hyperbolic Transformer and outperform existing Eu...\n",
            "  Chunk 2: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ...\n",
            "  Chunk 3: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ...\n",
            "  Chunk 4: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ...\n",
            "\n",
            "Referência: BIBREF0\n",
            "  Chunk 1: ...model largely follows the original transformer work [62]. We trained a 12-layer decoder-only transformer with masked self-attention heads (768 dime...\n",
            "  Chunk 2: ...full model. 6 Conclusion We introduced a framework for achieving strong natural language understanding with a single task-agnostic model through ge...\n",
            "  Chunk 3: ...(Dolan and Brockett, 2005), which aim to predict the relationships between sentences by analyzing them holistically, as well as token-level tasks s...\n",
            "  Chunk 4: ...(Dolan and Brockett, 2005), which aim to predict the relationships between sentences by analyzing them holistically, as well as token-level tasks s...\n",
            "  Chunk 5: ...of the pre-trained representations, especially for the fine-tuning approaches. The major limitation is that standard language models are unidirecti...\n",
            "\n",
            "Referência: BIBREF5\n",
            "  Chunk 1: ...2013; Bahdanau et al., 2015) that processes a sequence by replacing each element by a weighted average of the rest of the sequence. The original Tr...\n",
            "  Chunk 2: ...it has recently become more common to use models based on the “Transformer” architecture (Vaswani et al., 2017). The Transformer was initially show...\n",
            "  Chunk 3: ...we consider (Section 3.7). 3.1 Baseline Our goal for our baseline is to reflect typical, modern practice. We pre-train a standard Transformer (desc...\n",
            "  Chunk 4: ...we consider (Section 3.7). 3.1 Baseline Our goal for our baseline is to reflect typical, modern practice. We pre-train a standard Transformer (desc...\n",
            "  Chunk 5: ...“referent noun prediction” variant described above is a little more involved; we describe this process in Appendix B. 3. Experiments Recent advance...\n",
            "  Chunk 6: ...“referent noun prediction” variant described above is a little more involved; we describe this process in Appendix B. 3. Experiments Recent advance...\n",
            "  Chunk 7: ...“referent noun prediction” variant described above is a little more involved; we describe this process in Appendix B. 3. Experiments Recent advance...\n",
            "  Chunk 8: ...“referent noun prediction” variant described above is a little more involved; we describe this process in Appendix B. 3. Experiments Recent advance...\n",
            "\n",
            "Referência: BIBREF155\n",
            "  Chunk 1: ...text is generated. In this paper, we present PALM, a novel approach to Pre-training an Autoencoding&autoregressive Language Model for text generati...\n",
            "\n",
            "Referência: BIBREF8\n",
            "  Chunk 1: ...propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new selfsupervised objective. In PEGASUS, import...\n",
            "  Chunk 2: ...a strong combination of natural language understanding and generation. 7 Related Work Early methods for pretraining were based on language models. ...\n",
            "  Chunk 3: ...a strong combination of natural language understanding and generation. 7 Related Work Early methods for pretraining were based on language models. ...\n",
            "  Chunk 4: ...a strong combination of natural language understanding and generation. 7 Related Work Early methods for pretraining were based on language models. ...\n",
            "\n",
            "Referência: BIBREF98\n",
            "  Chunk 1: ...every task, which in practice means that a single set of hyperparameters can be used for effective fine-tuning on any downstream task. Similar unif...\n",
            "  Chunk 2: mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer Linting Xue∗ Noah Constant∗ Adam Roberts∗ Mihir Kale Rami Al-Rfou Aditya Siddhant A...\n",
            "  Chunk 3: ...Language Model Prompting The birth of GPT-3 (Brown et al., 2020) has blown people’s minds with its outstanding performance in multi-task and few-sh...\n",
            "  Chunk 4: ...Language Model Prompting The birth of GPT-3 (Brown et al., 2020) has blown people’s minds with its outstanding performance in multi-task and few-sh...\n",
            "\n",
            "Referência: BIBREF64\n",
            "  Chunk 1: ...Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In North America...\n",
            "  Chunk 2: ...Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In North America...\n",
            "  Chunk 3: ...et al., 2019; Joshi et al., 2019), are responsible for significant gains in many NLP tasks. Under the common paradigm, the model is pre-trained on ...\n",
            "\n",
            "Referência: BIBREF7\n",
            "  Chunk 1: ...from BERT, which was also trained for 1M steps on a combination of books and Wikipedia data. We compare the following approaches: Language Model Si...\n",
            "  Chunk 2: ...from BERT, which was also trained for 1M steps on a combination of books and Wikipedia data. We compare the following approaches: Language Model Si...\n",
            "\n",
            "Referência: BIBREF177\n",
            "  Chunk 1: ...model while being 14.9x smaller. 1 Introduction Transformer-based models have shown great power in various natural language processing (NLP) tasks....\n",
            "  Chunk 2: ...maintain competitive results on high-resource tasks, performing within two points of the state-of-theart on all tasks and setting a new state-of-th...\n",
            "  Chunk 3: ...maintain competitive results on high-resource tasks, performing within two points of the state-of-theart on all tasks and setting a new state-of-th...\n",
            "\n",
            "Referência: BIBREF174\n",
            "  Chunk 1: ...a teacher assistant (Mirzadeh et al., 2019) helps the distillation of large pre-trained Transformer based models and the proposed deep self-attenti...\n",
            "  Chunk 2: ...has a larger vocabulary of size 250k and ∼ 610M parameters. Pre-trained Models for MT There has been much recent progress in pre-training for NLP a...\n",
            "\n",
            "Referência: BIBREF171\n",
            "  Chunk 1: ...specially designed KD method for Transformer-based models. 2.1 Transformer Layer Most of the recent pre-trained language models (e.g., BERT, XLNet ...\n",
            "  Chunk 2: ...accuracy on the development set. We evaluate both DrQA and a simple unigram TF-IDF implementation to rank the sentences for selection. We further e...\n",
            "\n",
            "Referência: BIBREF170\n",
            "  Chunk 1: ...using much smaller language models pre-trained with knowledge distillation, resulting in models that are lighter and faster at inference time, whil...\n",
            "  Chunk 2: ...NLI To date, the primary sources of annotated NLI corpora have been the Recognizing Textual Entailment (RTE) challenge tasks.1 These are generally ...\n",
            "\n",
            "Referência: BIBREF176\n",
            "  Chunk 1: ...the Hessian spectrum. Compressed NLP model Notable examples for NLP compression work are LSTM and GRU-based models for machine translation and lang...\n",
            "  Chunk 2: ...answering task (McCann et al., 2018). This paradigm has recently proved to be effective for some structured prediction tasks, such as entity and re...\n",
            "  Chunk 3: ...answering task (McCann et al., 2018). This paradigm has recently proved to be effective for some structured prediction tasks, such as entity and re...\n",
            "\n",
            "Referência: BIBREF25\n",
            "  Chunk 1: ...Background and Methods We train language models on WebText2, an extended version of the WebText [RWC+19] dataset, tokenized using byte-pair encodin...\n",
            "\n",
            "Referência: BIBREF187\n",
            "  Chunk 1: ...train auto-encoders on unlabeled text, and then use the pre-trained model architecture and parameters as a starting point for other specific NLP mo...\n",
            "  Chunk 2: ...train auto-encoders on unlabeled text, and then use the pre-trained model architecture and parameters as a starting point for other specific NLP mo...\n",
            "\n",
            "Referência: BIBREF182\n",
            "  Chunk 1: ...We analyze four models, the computational requirements of which we describe below. All models have code freely available online, which we used out-...\n",
            "\n",
            "Referência: BIBREF188\n",
            "  Chunk 1: ...in machine reading comprehension. In ACL. Haoyu Wang, Ming Tan, Mo Yu, Shiyu Chang, Dakuo Wang, Kun Xu, Xiaoxiao Guo, and Saloni Potdar. 2019b. Ext...\n",
            "  Chunk 2: ...Chen, Xiaodan Zhu, Zhen-Hua Ling, Diana Inkpen, and Si Wei. 2018. Neural natural language inference models enhanced with external knowledge. In ACL...\n",
            "  Chunk 3: ...showed that language modeling, a type of simple generative model, can be effective for document ranking (Zhai, 2008; Lafferty and Zhai, 2001; Ponte...\n",
            "\n",
            "Referência: BIBREF186\n",
            "  Chunk 1: ...Here, Q contains the previous c words and the next c words. Note that |A| equals the number of internal anchors in the KB. As in past models, the c...\n",
            "\n",
            "Referência: BIBREF200\n",
            "  Chunk 1: ...based on the transformer model for a triplet (concept 1, relation, concept 2). The input of the transformer is of the format [CLS] concept1 [relati...\n",
            "  Chunk 2: An Empirical Survey of Data Augmentation for Limited Data Learning in NLP Jiaao Chen⋄∗ Derek Tam†∗ Colin Raffel† Mohit Bansal† Diyi Yang⋄ ⋄Georgia Ins...\n",
            "\n",
            "Referência: BIBREF201\n",
            "  Chunk 1: ...et al., 2020) which can hardly cover all the variations of biomedical names. In parallel, self-supervised learning has shown tremendous success in ...\n",
            "  Chunk 2: ...multi-label attention to capture better interaction between input tokens and individual output labels. X-BERT (Chang et al., 2019) fine-tuned pre-t...\n",
            "\n",
            "Referência: BIBREF198\n",
            "  Chunk 1: ...et al., 2013; Xu et al., 2014; Yoshikawa et al., 2017). Pre-trained Language Modeling Recently, deep contextual language model has been shown effec...\n",
            "  Chunk 2: Document Language Models, Query Models, and Risk Minimization for Information Retrieval John Lafferty School of Computer Science Carnegie Mellon Unive...\n",
            "\n",
            "Referência: BIBREF126\n",
            "  Chunk 1: ...(BERT) which used bidirectional transformers (Vaswani et al., 2017) to create context-dependent representations. For both models, pre-training is d...\n",
            "\n",
            "Referência: BIBREF203\n",
            "  Chunk 1: ...newly proposed semantic-level language model matrix S in the input in addition to W [as depicted in figure 1(b)], such that the input vector to the...\n",
            "  Chunk 2: ...augmentation, which is independent of the downstream learning models. Similar to our work, [16, 17] uses pretrained language models to generate syn...\n",
            "\n",
            "Referência: BIBREF196\n",
            "  Chunk 1: ...pre-training. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Ex...\n",
            "\n",
            "Referência: BIBREF205\n",
            "  Chunk 1: ...Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained Models for Natural Language Processing: A Survey. SCIENCE CHINA Technolo...\n",
            "  Chunk 2: The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20) Do Not Have Enough Data? Deep Learning to the Rescue! Ateret Anaby-Tavor,1 Boaz...\n",
            "\n",
            "Referência: BIBREF206\n",
            "  Chunk 1: ...performance. 7 Longformer-Encoder-Decoder (LED) The original Transformer (Vaswani et al., 2017) consisted of an encoder-decoder architecture, inten...\n",
            "  Chunk 2: ...task of generating novel event influence in unseen contexts is still an open challenge. Meanwhile, promising evidence from recent work attests to t...\n",
            "\n",
            "Referência: BIBREF209\n",
            "  Chunk 1: ...Transformer architecture (Vaswani et al., 2017) is widely used in natural language processing and yields state-of-the-art results on a number of ta...\n",
            "  Chunk 2: ...involve early feature-based models [1, 11, 17, 18, 20, 16, 21, 37] and recent deep learning models [5, 26, 43, 38, 27, 44, 14, 34, ?]. Open domain ...\n",
            "\n",
            "Referência: BIBREF208\n",
            "  Chunk 1: ...J. Carbonell, Q. V. Le, and R. Salakhutdinov. Transformer-xl: Attentive language models beyond a fixed-length context. arXiv:1901.02860, 2019. [22]...\n",
            "  Chunk 2: ...of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). Sen Yang...\n",
            "\n",
            "Referência: BIBREF210\n",
            "  Chunk 1: ...AND RELATED WORK Transformers (Vaswani et al., 2017; Dehghani et al., 2019) are powerful neural network architectures that have become SOTA in seve...\n",
            "  Chunk 2: ...quality and larger quantity in the target language from a source language (e.g. English) in an unsupervised way. In this work, we limit ourselves t...\n",
            "\n",
            "Referência: BIBREF207\n",
            "  Chunk 1: ...transformers. arXiv preprint arXiv:1904.10509. Gonc¸alo M Correia, Vlad Niculae, and Andr´e FT Martins. 2019. Adaptively sparse transformers. arXiv...\n",
            "  Chunk 2: ...layer and inputs from all preceding blocks in the previous layer. to model “entities\" as natural language phrases and relations as any concept that...\n",
            "\n",
            "Referência: BIBREF38\n",
            "  Chunk 1: ...2018) where random tokens in a sequence are masked and the model predicts the original tokens to learn the context. The success of pre-trained mode...\n",
            "  Chunk 2: ...et al., 2015); (2) the lack of gold alignments between nodes (concepts) in the graph and words in the text which limits attempts to rely on explici...\n",
            "\n",
            "Referência: BIBREF41\n",
            "  Chunk 1: ...[10], a selfsupervised [22] bidirectional language model. It employs multilayer transformers as its encoder and uses masked token prediction as its...\n",
            "  Chunk 2: ...Zhang et al., 2019)2, but the improvement of these models measured by the accuracy or F1 score has reached a bottleneck. One reason is that the tas...\n",
            "\n",
            "Referência: BIBREF37\n",
            "  Chunk 1: ...GraphCodeBERT, a graph-based pre-trained model based on Transformer for programming language. We introduce model architecture, graph-guided masked ...\n",
            "\n",
            "Referência: BIBREF157\n",
            "  Chunk 1: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1442–1459 November 7–11, 2021. c⃝2021 Association for Co...\n",
            "\n",
            "Referência: BIBREF158\n",
            "  Chunk 1: ...of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 1112–1122. Thomas Wolf, Lysandre Debut, Victor San...\n",
            "\n",
            "Referência: BIBREF202\n",
            "  Chunk 1: ...of Washington, Seattle, WA, USA {yiben.yang@,jared.fern@u.,jzwang@}northwestern.edu {chaitanyam,swabhas,ronanlb,chandrab,yejinc,dougd}@allenai.org ...\n",
            "\n",
            "Referência: BIBREF204\n",
            "  Chunk 1: ...that AE, AR, and Seq2Seq pre-trained models can be conditioned on labels by prepending label information and provide an effective way to augment tr...\n",
            "\n",
            "Referência: BIBREF236\n",
            "  Chunk 1: ...and data augmentation (Kaushik et al., 2020; Teney et al., 2020), whereas we focus on minimal edits changing model predictions for explanation. Con...\n",
            "\n",
            "Referência: BIBREF235\n",
            "  Chunk 1: ...al. 2013), contextual word vectors (Devlin et al. 2018) and deep contextualized LM models (Radford et al. 2019; Howard and Ruder 2018). Recent adva...\n",
            "\n",
            "Referência: BIBREF211\n",
            "  Chunk 1: ...Pierleoni. 2019. Deep bidirectional transformers for relation extraction without supervision. EMNLPIJCNLP 2019, page 67. Yifan Peng, Anthony Rios, ...\n",
            "\n",
            "Referência: BIBREF93\n",
            "  Chunk 1: ...show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can b...\n",
            "  Chunk 2: ...pretrained LMs. This is beneficial when serving models for multiple tasks. 2 Overview of AUTOPROMPT A natural way to elicit knowledge from pretrain...\n",
            "  Chunk 3: AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts Taylor Shin*♦ Yasaman Razeghi∗♦ Robert L. Logan IV∗♦ Eric Wa...\n",
            "\n",
            "Referência: BIBREF237\n",
            "  Chunk 1: ...extraction is a fundamental problem in constructing knowledge bases from unstructured text. The goal of relational extraction is to identify mentio...\n",
            "\n",
            "Referência: BIBREF212\n",
            "  Chunk 1: ...2019), establishing a new state-of-the-art on the latter. Our synthetic data generation models, for both question generation and answer extraction,...\n",
            "\n",
            "Referência: BIBREF214\n",
            "  Chunk 1: ...the generated training data can greatly benefit the multi-hop QA system in both unsupervised and few-shot learning settings. 2 Related Work Unsuper...\n",
            "\n",
            "Referência: BIBREF215\n",
            "  Chunk 1: ...Panupong Pasupat and Percy Liang. 2015. Compositional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the ...\n",
            "\n",
            "Referência: BIBREF244\n",
            "  Chunk 1: ...fine-tuned BERT-Q-a model (Mass et al., 2019). 3.4 BERT model for Q-to-q similarity The second BERT model, BERT-Q-q, is independent from the first ...\n",
            "\n",
            "Referência: BIBREF217\n",
            "  Chunk 1: ...Advances in neural information processing systems, pages 2672–2680. Rahul Gupta. 2019. Data augmentation for low resource sentiment analysis using ...\n",
            "\n",
            "Referência: BIBREF216\n",
            "  Chunk 1: ...review to a domain-independent review by masking its source-specific attributes, and then converts the domain-independent review to a target-domain...\n",
            "\n",
            "Referência: BIBREF257\n",
            "  Chunk 1: ...tasks. 7 Related Work Using Explicit Linguistic Information. Before pretrained contextualized representations emerged, linguistic information was c...\n",
            "\n",
            "Referência: BIBREF259\n",
            "  Chunk 1: ...pre-trained language models may furthermore enhance other downstream tasks such as various Natural Language Understanding (NLU) tasks (Zhang et al....\n",
            "\n",
            "Referência: BIBREF254\n",
            "  Chunk 1: ...Dyer, and G´abor Melis. Unsupervised recurrent neural network grammars. arXiv preprint arXiv:1904.03746, 2019. Guillaume Lample and Alexis Conneau....\n",
            "\n",
            "Referência: BIBREF248\n",
            "  Chunk 1: ...the sampled concatenation as input and trained on a task dataset. Empirical results on 6 tasks and 21 datasets show that our approach outperforms s...\n",
            "\n",
            "Referência: BIBREF9\n",
            "  Chunk 1: ...Joe Davison, Joshua Feldman, and Alexander Rush. 2019. Commonsense Knowledge Mining from Pretrained Models. In Proceedings of the 2019 Conference o...\n",
            "\n",
            "Referência: BIBREF19\n",
            "  Chunk 1: ...answering, natural language inference, sentiment analysis, and document ranking.1. 1 Introduction Unsupervised representation learning has been hig...\n",
            "  Chunk 2: ...the original data from corrupted input. A notable example is BERT [10], which has been the state-of-the-art pretraining approach. Given the input t...\n",
            "\n",
            "Referência: BIBREF18\n",
            "  Chunk 1: ...middle-school and high-school settings. 6 Related Work Pretraining methods have been designed with different training objectives, including languag...\n",
            "  Chunk 2: ...middle-school and high-school settings. 6 Related Work Pretraining methods have been designed with different training objectives, including languag...\n",
            "\n",
            "Referência: BIBREF15\n",
            "  Chunk 1: ...to scale the entire ELMo vector. γ is of practical importance to aid the optimization process (see supplemental material for details). Considering ...\n",
            "  Chunk 2: ...word sense. We show that similar signals are also induced by the modified language model objective of our ELMo representations, and it can be very ...\n",
            "\n",
            "Referência: BIBREF56\n",
            "  Chunk 1: ...relations. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Lang...\n",
            "\n",
            "Referência: BIBREF28\n",
            "  Chunk 1: . Invited Review. Pre-trained Models for Natural Language Processing: A Survey Xipeng Qiu*, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai & Xuanjing H...\n",
            "\n",
            "Referência: BIBREF10\n",
            "  Chunk 1: ...al., 2007; Bengio et al., 2007), which are all based on a similar approach: greedy layer-wise unsupervised pre-training followed by supervised fine...\n",
            "\n",
            "Referência: BIBREF12\n",
            "  Chunk 1: ...pre-trained using 127 (coarse) classes obtained after top-down clustering of the WordNet tree is comparable to a transfer performance after finetun...\n",
            "\n",
            "Referência: BIBREF17\n",
            "  Chunk 1: ...the positions of widely separated, relevant inputs in the input sequence do not matter. Unlike previous approaches, ours quickly learns to distingu...\n",
            "\n",
            "Referência: BIBREF167\n",
            "  Chunk 1: ...recently shown excellent results on many datasets, including entailment data (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2018). Conv...\n",
            "\n",
            "Referência: BIBREF169\n",
            "  Chunk 1: ...serve as a benchmark task for research on NLU. In this task, also known as recognizing textual entailment (Fyodorov et al., 2000; Condoravdi et al....\n",
            "\n",
            "Referência: BIBREF168\n",
            "  Chunk 1: Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections Ruiqi Zhong Kristy Lee∗ Zheng Zhang∗ Dan Klein Comput...\n",
            "\n",
            "Referência: BIBREF94\n",
            "  Chunk 1: ...present a particularly interesting approach with the T5 model. It treats all tasks as generative (text-to-text), eliminating the need for a taskspe...\n",
            "  Chunk 2: ...our baselines. Yet, in contrast to these works, the any-domain objective is a core principle of this study. Autoregressive LMs and Prompting Recent...\n",
            "\n",
            "Referência: BIBREF97\n",
            "  Chunk 1: Learning How to Ask: Querying LMs with Mixtures of Soft Prompts Guanghui Qin and Jason Eisner Department of Computer Science, Johns Hopkins University...\n",
            "  Chunk 2: Learning How to Ask: Querying LMs with Mixtures of Soft Prompts Guanghui Qin and Jason Eisner Department of Computer Science, Johns Hopkins University...\n",
            "\n",
            "Referência: BIBREF96\n",
            "  Chunk 1: ...projects by introducing (a) more effective techniques for optimizing prompts, and (b) a more comprehensive approach for accounting for the role of ...\n",
            "\n",
            "Referência: BIBREF95\n",
            "  Chunk 1: ...recently been shown to enable strong zero-shot generalization in the discriminative setting using large-scale contrastive learning [28, 14]. Also i...\n",
            "\n",
            "Referência: BIBREF76\n",
            "  Chunk 1: ...generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language...\n",
            "\n",
            "Referência: BIBREF178\n",
            "  Chunk 1: ...need of different ABSA problems, making it difficult to adapt the model from one to another. Motivated by recent success in formulating sev- 505 er...\n",
            "\n",
            "Referência: BIBREF180\n",
            "  Chunk 1: ...Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models for natural language processing: A survey. SCIENCE CHINA Technological...\n",
            "\n",
            "Referência: BIBREF191\n",
            "  Chunk 1: ...rate (e.g. [4]). The recently introduced sequence-to-sequence paradigm [1] removed these constraints by using one RNN to map an input sequence to a...\n",
            "\n",
            "Referência: BIBREF189\n",
            "  Chunk 1: ...generation-based approach to the document ranking task using pretrained sequence-to-sequence models. Our models outperform a classification-based a...\n",
            "\n",
            "Referência: BIBREF190\n",
            "  Chunk 1: ...documents identified by their unique titles (e.g., Wikipedia articles). 3 METHOD We address the retrieval problem with an sequence-to-sequence mode...\n",
            "\n",
            "Referência: BIBREF197\n",
            "  Chunk 1: ...of interest. Instead, we make a weaker assumption that we can get estimates of each document’s language model individu- ally without making inferen...\n",
            "\n",
            "=== Fim da Exibição das Citações e Chunks ===\n"
          ]
        }
      ],
      "source": [
        "# Esse código tem a finalidade de exibir todas as citações no dataset SurveySum,\n",
        "# junto com os chunks de texto correspondentes, caso existam.\n",
        "\n",
        "# Exibe todas as citações e os chunks correspondentes\n",
        "print(\"=== Exibindo Todas as Citações e Seus Chunks Correspondentes ===\\n\")\n",
        "\n",
        "# Cria um dicionário para armazenar todas as citações e seus chunks associados\n",
        "citations_dict = {}\n",
        "\n",
        "# Percorre cada entrada no dataset para coletar os chunks e suas citações\n",
        "for entrada in dataset['train']:\n",
        "    # Verifica se existem chunks de texto gerados\n",
        "    generated_text = entrada.get('generated_section_text')\n",
        "\n",
        "    if generated_text and 'autosurvey_t5_3b_10_chunks' in generated_text:\n",
        "        autosurvey = generated_text['autosurvey_t5_3b_10_chunks']\n",
        "\n",
        "        # Verifica se há referências e chunks para exibir\n",
        "        if 'references_sent_to_gpt' in autosurvey:\n",
        "            for ref_chunk in autosurvey['references_sent_to_gpt']:\n",
        "                bibref = ref_chunk.get('bibref', 'Sem referência')  # Identificador da citação\n",
        "                chunk_text = ref_chunk.get('chunk', 'Texto não disponível')  # Texto do chunk\n",
        "\n",
        "                # Adiciona o chunk ao dicionário de citações\n",
        "                if bibref not in citations_dict:\n",
        "                    citations_dict[bibref] = []\n",
        "                citations_dict[bibref].append(chunk_text)\n",
        "\n",
        "# Exibe todas as citações e seus chunks\n",
        "for bibref, chunks in citations_dict.items():\n",
        "    print(f\"\\nReferência: {bibref}\")\n",
        "    for i, chunk_text in enumerate(chunks, 1):\n",
        "        print(f\"  Chunk {i}: {chunk_text[:150]}...\")  # Limita a exibição do chunk a 150 caracteres\n",
        "\n",
        "print(\"\\n=== Fim da Exibição das Citações e Chunks ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUvzQxsc6w9I"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgIdj6dm7Y1r"
      },
      "source": [
        "### D. Contagem de Chunks por Citação e Totalização no Dataset SurveySum\n",
        "\n",
        "Este código calcula quantos chunks de texto estão associados a cada citação (identificadas por BIBREF) no dataset SurveySum e, ao final, exibe uma totalização do número de citações e chunks presentes. É útil para entender a distribuição e quantidade de informações (chunks) que cada citação traz para o dataset, fornecendo uma visão quantitativa da relação entre as fontes (citações) e os trechos de texto associados (chunks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUFjeHlX80wd",
        "outputId": "d4f10369-4b15-4906-8e2d-a2be8150a9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Contagem de Chunks por Citação ===\n",
            "Citação BIBREF358: 1 chunks\n",
            "Citação BIBREF179: 2 chunks\n",
            "Citação BIBREF306: 1 chunks\n",
            "Citação BIBREF355: 1 chunks\n",
            "Citação BIBREF199: 3 chunks\n",
            "Citação BIBREF354: 1 chunks\n",
            "Citação BIBREF357: 1 chunks\n",
            "Citação BIBREF356: 1 chunks\n",
            "Citação BIBREF312: 1 chunks\n",
            "Citação BIBREF316: 1 chunks\n",
            "Citação BIBREF70: 4 chunks\n",
            "Citação BIBREF104: 6 chunks\n",
            "Citação BIBREF71: 3 chunks\n",
            "Citação BIBREF16: 4 chunks\n",
            "Citação BIBREF166: 3 chunks\n",
            "Citação BIBREF81: 3 chunks\n",
            "Citação BIBREF82: 5 chunks\n",
            "Citação BIBREF80: 5 chunks\n",
            "Citação BIBREF127: 1 chunks\n",
            "Citação BIBREF14: 2 chunks\n",
            "Citação BIBREF89: 2 chunks\n",
            "Citação BIBREF90: 4 chunks\n",
            "Citação BIBREF91: 2 chunks\n",
            "Citação BIBREF92: 2 chunks\n",
            "Citação BIBREF88: 2 chunks\n",
            "Citação BIBREF87: 1 chunks\n",
            "Citação BIBREF86: 6 chunks\n",
            "Citação BIBREF21: 2 chunks\n",
            "Citação BIBREF20: 1 chunks\n",
            "Citação BIBREF13: 4 chunks\n",
            "Citação BIBREF85: 4 chunks\n",
            "Citação BIBREF84: 5 chunks\n",
            "Citação BIBREF83: 4 chunks\n",
            "Citação BIBREF79: 4 chunks\n",
            "Citação BIBREF78: 2 chunks\n",
            "Citação BIBREF137: 2 chunks\n",
            "Citação BIBREF3: 1 chunks\n",
            "Citação BIBREF142: 1 chunks\n",
            "Citação BIBREF175: 3 chunks\n",
            "Citação BIBREF143: 1 chunks\n",
            "Citação BIBREF141: 1 chunks\n",
            "Citação BIBREF1: 1 chunks\n",
            "Citação BIBREF140: 1 chunks\n",
            "Citação BIBREF144: 1 chunks\n",
            "Citação BIBREF118: 2 chunks\n",
            "Citação BIBREF116: 2 chunks\n",
            "Citação BIBREF119: 3 chunks\n",
            "Citação BIBREF120: 4 chunks\n",
            "Citação BIBREF115: 2 chunks\n",
            "Citação BIBREF114: 1 chunks\n",
            "Citação BIBREF117: 2 chunks\n",
            "Citação BIBREF109: 2 chunks\n",
            "Citação BIBREF112: 1 chunks\n",
            "Citação BIBREF110: 4 chunks\n",
            "Citação BIBREF66: 3 chunks\n",
            "Citação BIBREF111: 2 chunks\n",
            "Citação BIBREF108: 2 chunks\n",
            "Citação BIBREF113: 4 chunks\n",
            "Citação BIBREF133: 2 chunks\n",
            "Citação BIBREF131: 1 chunks\n",
            "Citação BIBREF128: 2 chunks\n",
            "Citação BIBREF135: 2 chunks\n",
            "Citação BIBREF129: 2 chunks\n",
            "Citação BIBREF130: 1 chunks\n",
            "Citação BIBREF132: 3 chunks\n",
            "Citação BIBREF134: 3 chunks\n",
            "Citação BIBREF45: 4 chunks\n",
            "Citação BIBREF106: 2 chunks\n",
            "Citação BIBREF107: 2 chunks\n",
            "Citação BIBREF61: 1 chunks\n",
            "Citação BIBREF24: 2 chunks\n",
            "Citação BIBREF105: 3 chunks\n",
            "Citação BIBREF67: 3 chunks\n",
            "Citação BIBREF102: 1 chunks\n",
            "Citação BIBREF100: 3 chunks\n",
            "Citação BIBREF68: 3 chunks\n",
            "Citação BIBREF101: 1 chunks\n",
            "Citação BIBREF99: 3 chunks\n",
            "Citação BIBREF103: 2 chunks\n",
            "Citação BIBREF65: 4 chunks\n",
            "Citação BIBREF69: 4 chunks\n",
            "Citação BIBREF27: 2 chunks\n",
            "Citação BIBREF35: 2 chunks\n",
            "Citação BIBREF32: 1 chunks\n",
            "Citação BIBREF36: 3 chunks\n",
            "Citação BIBREF33: 5 chunks\n",
            "Citação BIBREF26: 6 chunks\n",
            "Citação BIBREF4: 3 chunks\n",
            "Citação BIBREF31: 2 chunks\n",
            "Citação BIBREF34: 3 chunks\n",
            "Citação BIBREF30: 2 chunks\n",
            "Citação BIBREF11: 2 chunks\n",
            "Citação BIBREF51: 3 chunks\n",
            "Citação BIBREF42: 3 chunks\n",
            "Citação BIBREF55: 2 chunks\n",
            "Citação BIBREF48: 3 chunks\n",
            "Citação BIBREF46: 3 chunks\n",
            "Citação BIBREF57: 2 chunks\n",
            "Citação BIBREF59: 1 chunks\n",
            "Citação BIBREF2: 1 chunks\n",
            "Citação BIBREF151: 1 chunks\n",
            "Citação BIBREF152: 1 chunks\n",
            "Citação BIBREF287: 1 chunks\n",
            "Citação BIBREF233: 1 chunks\n",
            "Citação BIBREF219: 2 chunks\n",
            "Citação BIBREF241: 3 chunks\n",
            "Citação BIBREF245: 3 chunks\n",
            "Citação BIBREF243: 3 chunks\n",
            "Citação BIBREF165: 3 chunks\n",
            "Citação BIBREF247: 3 chunks\n",
            "Citação BIBREF161: 2 chunks\n",
            "Citação BIBREF289: 1 chunks\n",
            "Citação BIBREF159: 3 chunks\n",
            "Citação BIBREF156: 2 chunks\n",
            "Citação BIBREF54: 3 chunks\n",
            "Citação BIBREF299: 1 chunks\n",
            "Citação BIBREF181: 3 chunks\n",
            "Citação BIBREF297: 1 chunks\n",
            "Citação BIBREF298: 1 chunks\n",
            "Citação BIBREF77: 2 chunks\n",
            "Citação BIBREF184: 2 chunks\n",
            "Citação BIBREF183: 2 chunks\n",
            "Citação BIBREF47: 2 chunks\n",
            "Citação BIBREF44: 2 chunks\n",
            "Citação BIBREF292: 1 chunks\n",
            "Citação BIBREF293: 1 chunks\n",
            "Citação BIBREF296: 1 chunks\n",
            "Citação BIBREF295: 1 chunks\n",
            "Citação BIBREF294: 1 chunks\n",
            "Citação BIBREF290: 1 chunks\n",
            "Citação BIBREF291: 1 chunks\n",
            "Citação BIBREF218: 1 chunks\n",
            "Citação BIBREF230: 2 chunks\n",
            "Citação BIBREF213: 2 chunks\n",
            "Citação BIBREF226: 1 chunks\n",
            "Citação BIBREF224: 2 chunks\n",
            "Citação BIBREF229: 2 chunks\n",
            "Citação BIBREF225: 2 chunks\n",
            "Citação BIBREF227: 2 chunks\n",
            "Citação BIBREF228: 1 chunks\n",
            "Citação BIBREF223: 2 chunks\n",
            "Citação BIBREF221: 1 chunks\n",
            "Citação BIBREF222: 1 chunks\n",
            "Citação BIBREF232: 1 chunks\n",
            "Citação BIBREF231: 2 chunks\n",
            "Citação BIBREF220: 2 chunks\n",
            "Citação BIBREF246: 2 chunks\n",
            "Citação BIBREF238: 2 chunks\n",
            "Citação BIBREF240: 2 chunks\n",
            "Citação BIBREF239: 3 chunks\n",
            "Citação BIBREF242: 2 chunks\n",
            "Citação BIBREF258: 2 chunks\n",
            "Citação BIBREF253: 2 chunks\n",
            "Citação BIBREF256: 2 chunks\n",
            "Citação BIBREF185: 3 chunks\n",
            "Citação BIBREF252: 1 chunks\n",
            "Citação BIBREF251: 1 chunks\n",
            "Citação BIBREF255: 2 chunks\n",
            "Citação BIBREF23: 1 chunks\n",
            "Citação BIBREF53: 2 chunks\n",
            "Citação BIBREF52: 2 chunks\n",
            "Citação BIBREF49: 2 chunks\n",
            "Citação BIBREF50: 2 chunks\n",
            "Citação BIBREF122: 2 chunks\n",
            "Citação BIBREF121: 2 chunks\n",
            "Citação BIBREF60: 3 chunks\n",
            "Citação BIBREF125: 1 chunks\n",
            "Citação BIBREF39: 3 chunks\n",
            "Citação BIBREF73: 1 chunks\n",
            "Citação BIBREF62: 2 chunks\n",
            "Citação BIBREF40: 3 chunks\n",
            "Citação BIBREF63: 2 chunks\n",
            "Citação BIBREF72: 4 chunks\n",
            "Citação BIBREF0: 5 chunks\n",
            "Citação BIBREF5: 8 chunks\n",
            "Citação BIBREF155: 1 chunks\n",
            "Citação BIBREF8: 4 chunks\n",
            "Citação BIBREF98: 4 chunks\n",
            "Citação BIBREF64: 3 chunks\n",
            "Citação BIBREF7: 2 chunks\n",
            "Citação BIBREF177: 3 chunks\n",
            "Citação BIBREF174: 2 chunks\n",
            "Citação BIBREF171: 2 chunks\n",
            "Citação BIBREF170: 2 chunks\n",
            "Citação BIBREF176: 3 chunks\n",
            "Citação BIBREF25: 1 chunks\n",
            "Citação BIBREF187: 2 chunks\n",
            "Citação BIBREF182: 1 chunks\n",
            "Citação BIBREF188: 3 chunks\n",
            "Citação BIBREF186: 1 chunks\n",
            "Citação BIBREF200: 2 chunks\n",
            "Citação BIBREF201: 2 chunks\n",
            "Citação BIBREF198: 2 chunks\n",
            "Citação BIBREF126: 1 chunks\n",
            "Citação BIBREF203: 2 chunks\n",
            "Citação BIBREF196: 1 chunks\n",
            "Citação BIBREF205: 2 chunks\n",
            "Citação BIBREF206: 2 chunks\n",
            "Citação BIBREF209: 2 chunks\n",
            "Citação BIBREF208: 2 chunks\n",
            "Citação BIBREF210: 2 chunks\n",
            "Citação BIBREF207: 2 chunks\n",
            "Citação BIBREF38: 2 chunks\n",
            "Citação BIBREF41: 2 chunks\n",
            "Citação BIBREF37: 1 chunks\n",
            "Citação BIBREF157: 1 chunks\n",
            "Citação BIBREF158: 1 chunks\n",
            "Citação BIBREF202: 1 chunks\n",
            "Citação BIBREF204: 1 chunks\n",
            "Citação BIBREF236: 1 chunks\n",
            "Citação BIBREF235: 1 chunks\n",
            "Citação BIBREF211: 1 chunks\n",
            "Citação BIBREF93: 3 chunks\n",
            "Citação BIBREF237: 1 chunks\n",
            "Citação BIBREF212: 1 chunks\n",
            "Citação BIBREF214: 1 chunks\n",
            "Citação BIBREF215: 1 chunks\n",
            "Citação BIBREF244: 1 chunks\n",
            "Citação BIBREF217: 1 chunks\n",
            "Citação BIBREF216: 1 chunks\n",
            "Citação BIBREF257: 1 chunks\n",
            "Citação BIBREF259: 1 chunks\n",
            "Citação BIBREF254: 1 chunks\n",
            "Citação BIBREF248: 1 chunks\n",
            "Citação BIBREF9: 1 chunks\n",
            "Citação BIBREF19: 2 chunks\n",
            "Citação BIBREF18: 2 chunks\n",
            "Citação BIBREF15: 2 chunks\n",
            "Citação BIBREF56: 1 chunks\n",
            "Citação BIBREF28: 1 chunks\n",
            "Citação BIBREF10: 1 chunks\n",
            "Citação BIBREF12: 1 chunks\n",
            "Citação BIBREF17: 1 chunks\n",
            "Citação BIBREF167: 1 chunks\n",
            "Citação BIBREF169: 1 chunks\n",
            "Citação BIBREF168: 1 chunks\n",
            "Citação BIBREF94: 2 chunks\n",
            "Citação BIBREF97: 2 chunks\n",
            "Citação BIBREF96: 1 chunks\n",
            "Citação BIBREF95: 1 chunks\n",
            "Citação BIBREF76: 1 chunks\n",
            "Citação BIBREF178: 1 chunks\n",
            "Citação BIBREF180: 1 chunks\n",
            "Citação BIBREF191: 1 chunks\n",
            "Citação BIBREF189: 1 chunks\n",
            "Citação BIBREF190: 1 chunks\n",
            "Citação BIBREF197: 1 chunks\n",
            "\n",
            "=== Totalização ===\n",
            "Total de citações com chunks: 247\n",
            "Total de chunks: 501\n"
          ]
        }
      ],
      "source": [
        "# Esse código tem a finalidade de contar quantos chunks estão associados a cada citação (BIBREF)\n",
        "# e exibir uma totalização de chunks e citações ao final.\n",
        "\n",
        "# Dicionário para armazenar a contagem de chunks para cada citação\n",
        "chunks_por_citacao = {}\n",
        "\n",
        "# Variável para contar o total de chunks\n",
        "total_chunks = 0\n",
        "\n",
        "# Percorre cada entrada no dataset para coletar os chunks e suas citações\n",
        "for entrada in dataset['train']:\n",
        "    # Verifica se existem chunks de texto gerados\n",
        "    generated_text = entrada.get('generated_section_text')\n",
        "\n",
        "    if generated_text and 'autosurvey_t5_3b_10_chunks' in generated_text:\n",
        "        autosurvey = generated_text['autosurvey_t5_3b_10_chunks']\n",
        "\n",
        "        # Verifica se há referências e chunks para contabilizar\n",
        "        if 'references_sent_to_gpt' in autosurvey:\n",
        "            for ref_chunk in autosurvey['references_sent_to_gpt']:\n",
        "                bibref = ref_chunk.get('bibref', 'Sem referência')  # Identificador da citação\n",
        "\n",
        "                # Incrementa a contagem de chunks para a citação específica\n",
        "                if bibref not in chunks_por_citacao:\n",
        "                    chunks_por_citacao[bibref] = 0\n",
        "                chunks_por_citacao[bibref] += 1\n",
        "\n",
        "                # Incrementa o contador total de chunks\n",
        "                total_chunks += 1\n",
        "\n",
        "# Exibe a quantidade de chunks para cada citação\n",
        "print(\"=== Contagem de Chunks por Citação ===\")\n",
        "for bibref, count in chunks_por_citacao.items():\n",
        "    print(f\"Citação {bibref}: {count} chunks\")\n",
        "\n",
        "# Exibe a totalização de chunks e citações\n",
        "total_citacoes = len(chunks_por_citacao)\n",
        "print(\"\\n=== Totalização ===\")\n",
        "print(f\"Total de citações com chunks: {total_citacoes}\")\n",
        "print(f\"Total de chunks: {total_chunks}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBH4euc8Kdt"
      },
      "source": [
        "### E. Exibição Enumerada dos Títulos de Surveys e Seções no Dataset SurveySum\n",
        "\n",
        "Este código exibe os títulos dos surveys e suas respectivas seções no dataset SurveySum, enumerando cada entrada para facilitar a visualização e compreensão da estrutura do dataset. É útil para uma exploração inicial do dataset, oferecendo uma visão geral de todos os surveys e suas seções, permitindo identificar temas e estrutura de conteúdo presentes no SurveySum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtTKT0Bkt2tm",
        "outputId": "04a670bc-dfce-45a0-859b-4eb4155baf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survey 1:\n",
            "Survey Title: A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions\n",
            "Section Title: Datasets::MIDI\n",
            "\n",
            "Survey 2:\n",
            "Survey Title: A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future\n",
            "Section Title: Discussion::Comparison between Verification/Refinement and Planning\n",
            "\n",
            "Survey 3:\n",
            "Survey Title: A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future\n",
            "Section Title: Methods::XoT Structural Variants::Tree Structure\n",
            "\n",
            "Survey 4:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Applications::Adversarial Examples (AVEs)\n",
            "\n",
            "Survey 5:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Applications::Few-Shot Learning\n",
            "\n",
            "Survey 6:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Applications::Fixing Class Imbalance\n",
            "\n",
            "Survey 7:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Applications::Mitigating Bias\n",
            "\n",
            "Survey 8:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Challenges & Future Directions\n",
            "\n",
            "Survey 9:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Data-to-Text NLG\n",
            "\n",
            "Survey 10:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Grammatical Error Correction (GEC)\n",
            "\n",
            "Survey 11:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Multimodal Tasks\n",
            "\n",
            "Survey 12:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Open-Ended & Conditional Generation\n",
            "\n",
            "Survey 13:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Parsing Tasks\n",
            "\n",
            "Survey 14:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Question Answering (QA)\n",
            "\n",
            "Survey 15:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Tasks::Sequence Tagging Tasks\n",
            "\n",
            "Survey 16:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Techniques & Methods::Example Interpolation Techniques\n",
            "\n",
            "Survey 17:\n",
            "Survey Title: A Survey of Data Augmentation Approaches for NLP\n",
            "Section Title: Techniques & Methods::Model-Based Techniques\n",
            "\n",
            "Survey 18:\n",
            "Survey Title: A Unified Framework for Generative Data Augmentation: A Comprehensive Survey\n",
            "Section Title: Data Selection\n",
            "\n",
            "Survey 19:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Better Position Encoding Mechanisms\n",
            "\n",
            "Survey 20:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Beyond Vanilla Fine-tuning\n",
            "\n",
            "Survey 21:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Compact Models\n",
            "\n",
            "Survey 22:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Improving existing T-PTLMs\n",
            "\n",
            "Survey 23:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Mitigating Bias\n",
            "\n",
            "Survey 24:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Novel Adaptation Methods\n",
            "\n",
            "Survey 25:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Privacy Issues\n",
            "\n",
            "Survey 26:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Discussions and Future Directions::Robustness to Noise\n",
            "\n",
            "Survey 27:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Downstream Adaptation Methods::Fine-tuning::Intermediate Fine-Tuning (IFT)\n",
            "\n",
            "Survey 28:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Downstream Adaptation Methods::Fine-tuning::Multi-task Fine-Tuning (MTFT)\n",
            "\n",
            "Survey 29:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Downstream Adaptation Methods::Prompt-based Tuning\n",
            "\n",
            "Survey 30:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Evaluation::Intrinsic Evaluation\n",
            "\n",
            "Survey 31:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Self-Supervised Learning (SSL)\n",
            "\n",
            "Survey 32:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: T-PTLM Core Concepts::Embeddings\n",
            "\n",
            "Survey 33:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: T-PTLM Core Concepts::Embeddings::Main Embeddings\n",
            "\n",
            "Survey 34:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: T-PTLM Core Concepts::Types of Pretraining Methods::Continual Pretraining (CPT)\n",
            "\n",
            "Survey 35:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: T-PTLM Core Concepts::Types of Pretraining Methods::Knowledge Inherited Pretraining (KIPT)\n",
            "\n",
            "Survey 36:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: T-PTLM Core Concepts::Types of Pretraining Methods::Simultaneous Pretraining (SPT)\n",
            "\n",
            "Survey 37:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Architecture::Decoder-based\n",
            "\n",
            "Survey 38:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Architecture::Encoder-Decoder based\n",
            "\n",
            "Survey 39:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Character-based T-PTLMs\n",
            "\n",
            "Survey 40:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Compact T-PTLMs\n",
            "\n",
            "Survey 41:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Green T-PTLMs\n",
            "\n",
            "Survey 42:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Knowledge Enriched T-PTLMs\n",
            "\n",
            "Survey 43:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Long-Sequence T-PTLMs\n",
            "\n",
            "Survey 44:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Extensions::Tokenization-Free T-PLTMs\n",
            "\n",
            "Survey 45:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Pretraining Corpus-based::Domain-Specific Models\n",
            "\n",
            "Survey 46:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::Pretraining Corpus-based::Social Media-based\n",
            "\n",
            "Survey 47:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::SSL::Adversarial SSL\n",
            "\n",
            "Survey 48:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::SSL::Contrastive SSL\n",
            "\n",
            "Survey 49:\n",
            "Survey Title: AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing\n",
            "Section Title: Taxonomy::SSL::Generative SSL\n",
            "\n",
            "Survey 50:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::Augmenting NLP Models with Automatically Generated Data\n",
            "\n",
            "Survey 51:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Explaining Models' Decisions\n",
            "\n",
            "Survey 52:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Inference Rule Generation\n",
            "\n",
            "Survey 53:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Information Extraction (IE)\n",
            "\n",
            "Survey 54:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Knowledge Extraction\n",
            "\n",
            "Survey 55:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Question Answering (QA)\n",
            "\n",
            "Survey 56:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Question Generation\n",
            "\n",
            "Survey 57:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Data Generation via PLM::::Sentiment Analysis (SA)\n",
            "\n",
            "Survey 58:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Discussion::Is explicit linguistic information needed?\n",
            "\n",
            "Survey 59:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Discussion::Mix of paradigms or PLMs.\n",
            "\n",
            "Survey 60:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::Fine-Tuning: Applying PLMs to NLP Tasks::Contextual Embeddings\n",
            "\n",
            "Survey 61:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::Fine-Tuning: Applying PLMs to NLP Tasks::Fine-tuning the PLM\n",
            "\n",
            "Survey 62:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::Fine-Tuning: Applying PLMs to NLP Tasks::Fine-tuning the PLM in Customized Models\n",
            "\n",
            "Survey 63:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::Modern Pre-Trained Language Models::Encoder-Decoder Language Models\n",
            "\n",
            "Survey 64:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::Modern Pre-Trained Language Models::Masked Language Models\n",
            "\n",
            "Survey 65:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 1: Pre-Train then Fine-Tune::The Beginnings of the Paradigm Shift\n",
            "\n",
            "Survey 66:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Learning from Proxy Tasks::Textual Entailment as Proxy Task\n",
            "\n",
            "Survey 67:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Answer Generation\n",
            "\n",
            "Survey 68:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Applications of Template-based Methods::Information Extraction (IE).\n",
            "\n",
            "Survey 69:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Applications of Template-based Methods::Other tasks.\n",
            "\n",
            "Survey 70:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Task-specific Tuning\n",
            "\n",
            "Survey 71:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Template Construction::Automatically-generated Continuous Templates.\n",
            "\n",
            "Survey 72:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Template Construction::Automatically-generated Discrete Templates.\n",
            "\n",
            "Survey 73:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Template Construction::Multi-Prompt Learning\n",
            "\n",
            "Survey 74:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 2: Prompt-based Learning::Template-based Learning::Template Design\n",
            "\n",
            "Survey 75:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 3: NLP as Text Generation\n",
            "\n",
            "Survey 76:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 3: NLP as Text Generation::Reformulating NLP Tasks as Text Generation Problems\n",
            "\n",
            "Survey 77:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 3: NLP as Text Generation::Generating Label-Augmented Texts\n",
            "\n",
            "Survey 78:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 3: NLP as Text Generation::Generating Word Indices\n",
            "\n",
            "Survey 79:\n",
            "Survey Title: Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey\n",
            "Section Title: Paradigm 3: NLP as Text Generation::Ranking Input-Output Pairs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Exibir os títulos das seções (section_title) e os títulos dos surveys (survey_title) enumerados\n",
        "for i in range(79):\n",
        "    print(f\"Survey {i+1}:\")\n",
        "    print(f\"Survey Title: {dataset['train'][i]['survey_title']}\")\n",
        "    print(f\"Section Title: {dataset['train'][i]['section_title']}\")\n",
        "    print()  # Linha em branco para separar cada survey\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch"
      ],
      "metadata": {
        "id": "-bCrdZo27DR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sentence_transformers.util import pytorch_cos_sim\n",
        "\n",
        "# Carregar o modelo e tokenizer do SciBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "scibert_model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "\n",
        "# Função para gerar embeddings com o SciBERT\n",
        "def gerar_embedding_scibert(texto):\n",
        "    \"\"\"\n",
        "    Gera o embedding para um texto usando SciBERT.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto: string com o texto a ser embeddado.\n",
        "\n",
        "    Retorna:\n",
        "    - tensor de embedding do SciBERT para o texto.\n",
        "    \"\"\"\n",
        "    tokens = tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = scibert_model(**tokens)\n",
        "    # Pegando a média das representações da última camada para obter o embedding final\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "# Função para recuperar os chunks mais relevantes com base na similaridade\n",
        "def recuperar_chunks_relevantes_scibert(entrada, num_chunks=5):\n",
        "    \"\"\"\n",
        "    Recupera os 'num_chunks' mais relevantes de uma entrada específica do dataset com base na similaridade de embeddings com SciBERT.\n",
        "\n",
        "    Parâmetros:\n",
        "    - entrada: dicionário com os dados de uma seção do dataset.\n",
        "    - num_chunks: número de chunks mais relevantes a serem selecionados.\n",
        "\n",
        "    Retorna:\n",
        "    - lista de tuplas (similaridade, chunk) para os chunks mais relevantes.\n",
        "    \"\"\"\n",
        "    # Obter o título da seção e gerar embedding\n",
        "    titulo_secao = entrada['section_title']\n",
        "    titulo_embedding = gerar_embedding_scibert(titulo_secao)\n",
        "\n",
        "    # Extrair os chunks de 'references_sent_to_gpt' e gerar embeddings\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks]\n",
        "    chunks_embeddings = torch.cat([gerar_embedding_scibert(chunk) for chunk in chunks_textos])\n",
        "\n",
        "    # Calcular a similaridade entre o título e cada chunk\n",
        "    similaridades = pytorch_cos_sim(titulo_embedding, chunks_embeddings).squeeze(0)\n",
        "\n",
        "    # Ordenar os chunks pela similaridade e selecionar os mais relevantes\n",
        "    indices_relevantes = torch.topk(similaridades, k=min(num_chunks, len(chunks_textos))).indices\n",
        "    chunks_relevantes = [(similaridades[i].item(), chunks_textos[i]) for i in indices_relevantes]\n",
        "\n",
        "    return chunks_relevantes\n",
        "\n",
        "# Testando a função com a primeira entrada do dataset\n",
        "entrada_exemplo = dataset['train'][10]  # Seleciona a primeira entrada do dataset para teste\n",
        "chunks_relevantes_exemplo = recuperar_chunks_relevantes_scibert(entrada_exemplo)  # Recupera os chunks relevantes\n",
        "print(\"Chunks Relevantes Selecionados:\\n\")  # Exibe os chunks relevantes\n",
        "\n",
        "# Exibe os chunks selecionados de forma enumerada\n",
        "for i, chunk in enumerate(chunks_relevantes_exemplo, 1):\n",
        "    print(f\"{i}. Similaridade: {chunk[0]:.4f} | Chunk: {chunk[1][:100]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6bUCM1FDDCr",
        "outputId": "2bc9fd5a-80de-40a8-db30-b31af9c2edd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks Relevantes Selecionados:\n",
            "\n",
            "1. Similaridade: 0.6880 | Chunk: ...Data Augmentation. Compared to vision, a few efforts have been done on augmenting text for classi...\n",
            "2. Similaridade: 0.6456 | Chunk: ...of labeled multimodal data, we propose a Multimodal Data Augmentation (MDA) framework for boostin...\n",
            "3. Similaridade: 0.6395 | Chunk: ...Data augmentation has a long history in image processing (Shorten and Khoshgoftaar, 2019). In lan...\n",
            "4. Similaridade: 0.6388 | Chunk: ...as it only uses text data, but provides only modest improvements in performance. And while multil...\n",
            "5. Similaridade: 0.6208 | Chunk: ...generated by our method improves IQA performance as compared to the baseline trained with the ori...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from sentence_transformers.util import pytorch_cos_sim\n",
        "\n",
        "# Carregar o modelo e tokenizer do SciBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "scibert_model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "\n",
        "# Função para gerar embeddings com o SciBERT\n",
        "def gerar_embedding_scibert(texto):\n",
        "    \"\"\"\n",
        "    Gera o embedding para um texto usando SciBERT.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto: string com o texto a ser embeddado.\n",
        "\n",
        "    Retorna:\n",
        "    - tensor de embedding do SciBERT para o texto.\n",
        "    \"\"\"\n",
        "    tokens = tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = scibert_model(**tokens)\n",
        "    # Pegando a média das representações da última camada para obter o embedding final\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "# Função para recuperar os chunks mais relevantes com base na similaridade\n",
        "def recuperar_chunks_relevantes_scibert(entrada, num_chunks=5):\n",
        "    \"\"\"\n",
        "    Recupera os 'num_chunks' mais relevantes de uma entrada específica do dataset com base na similaridade de embeddings com SciBERT.\n",
        "\n",
        "    Parâmetros:\n",
        "    - entrada: dicionário com os dados de uma seção do dataset.\n",
        "    - num_chunks: número de chunks mais relevantes a serem selecionados.\n",
        "\n",
        "    Retorna:\n",
        "    - lista de tuplas (similaridade, chunk) para os chunks mais relevantes.\n",
        "    \"\"\"\n",
        "    # Obter o título da seção e gerar embedding\n",
        "    titulo_secao = entrada['section_title']\n",
        "    titulo_embedding = gerar_embedding_scibert(titulo_secao)\n",
        "\n",
        "    # Extrair os chunks de 'references_sent_to_gpt' e gerar embeddings\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks]\n",
        "    chunks_embeddings = torch.cat([gerar_embedding_scibert(chunk) for chunk in chunks_textos])\n",
        "\n",
        "    # Calcular a similaridade entre o título e cada chunk\n",
        "    similaridades = pytorch_cos_sim(titulo_embedding, chunks_embeddings).squeeze(0)\n",
        "\n",
        "    # Ordenar os chunks pela similaridade e selecionar os mais relevantes\n",
        "    indices_relevantes = torch.topk(similaridades, k=min(num_chunks, len(chunks_textos))).indices\n",
        "    chunks_relevantes = [(similaridades[i].item(), chunks_textos[i]) for i in indices_relevantes]\n",
        "\n",
        "    return chunks_relevantes\n",
        "\n",
        "# Função para calcular a média das similaridades dos chunks relevantes\n",
        "def calcular_media_similaridade(chunks_relevantes):\n",
        "    \"\"\"\n",
        "    Calcula a média das similaridades dos chunks relevantes.\n",
        "\n",
        "    Parâmetros:\n",
        "    - chunks_relevantes: lista de tuplas (similaridade, chunk)\n",
        "\n",
        "    Retorna:\n",
        "    - média das similaridades\n",
        "    \"\"\"\n",
        "    similaridades = [sim for sim, _ in chunks_relevantes]\n",
        "    media_similaridade = sum(similaridades) / len(similaridades) if similaridades else 0\n",
        "    return media_similaridade\n",
        "\n",
        "# Testando a função com a primeira entrada do dataset\n",
        "entrada_exemplo = dataset['train'][0]  # Seleciona uma entrada do dataset para teste\n",
        "chunks_relevantes_exemplo = recuperar_chunks_relevantes_scibert(entrada_exemplo)  # Recupera os chunks relevantes\n",
        "print(\"Chunks Relevantes Selecionados:\\n\")  # Exibe os chunks relevantes\n",
        "\n",
        "# Exibe os chunks selecionados de forma enumerada\n",
        "for i, chunk in enumerate(chunks_relevantes_exemplo, 1):\n",
        "    print(f\"{i}. Similaridade: {chunk[0]:.4f} | Chunk: {chunk[1][:100]}...\")\n",
        "\n",
        "# Calcula e exibe a média das similaridades\n",
        "media_similaridade = calcular_media_similaridade(chunks_relevantes_exemplo)\n",
        "print(f\"\\nMédia de Similaridade dos Chunks Relevantes: {media_similaridade:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELsDTbchGEag",
        "outputId": "eafcd4b7-2bd5-4ee4-ed4c-a31b2fc9f31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks Relevantes Selecionados:\n",
            "\n",
            "1. Similaridade: 0.5814 | Chunk: ...proposed ficta hurt the harmony. One of the main advantages of the music21 framework is making su...\n",
            "2. Similaridade: 0.5663 | Chunk: ...note to be off. Using regularization methods such as weight decay has not proven efficient. We be...\n",
            "3. Similaridade: 0.5546 | Chunk: ...on the result, fine-tunes them in note-level. A listening test with professional pianists shows t...\n",
            "4. Similaridade: 0.5444 | Chunk: ...many research areas, including 1) Computer-based musical analysis (Volk et al., 2011; Meredith, 2...\n",
            "5. Similaridade: 0.5420 | Chunk: ...FUTURE OF THE DATASET Time will tell how useful the MSD proves to be, but here are our thoughts r...\n",
            "\n",
            "Média de Similaridade dos Chunks Relevantes: 0.5577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Função para calcular a média de similaridade dos chunks relevantes para todos os exemplos do dataset\n",
        "def calcular_medias_dataset(dataset, num_chunks=5):\n",
        "    \"\"\"\n",
        "    Calcula a média de similaridade dos chunks mais relevantes para cada entrada no dataset.\n",
        "\n",
        "    Parâmetros:\n",
        "    - dataset: dataset contendo as entradas.\n",
        "    - num_chunks: número de chunks mais relevantes a serem selecionados.\n",
        "\n",
        "    Retorna:\n",
        "    - lista com as médias de similaridade para cada entrada.\n",
        "    \"\"\"\n",
        "    medias_similaridade = []\n",
        "\n",
        "    for entrada in dataset['train']:\n",
        "        try:\n",
        "            chunks_relevantes = recuperar_chunks_relevantes_scibert(entrada, num_chunks=num_chunks)\n",
        "            media_similaridade = calcular_media_similaridade(chunks_relevantes)\n",
        "            medias_similaridade.append(media_similaridade)\n",
        "        except KeyError:\n",
        "            print(\"Formato inesperado em entrada. Ignorando entrada.\")\n",
        "            continue\n",
        "\n",
        "    return medias_similaridade\n",
        "\n",
        "# Calcula as médias de similaridade para todo o dataset\n",
        "medias_similaridade_dataset = calcular_medias_dataset(dataset)\n",
        "\n",
        "# Plota o gráfico das médias de similaridade\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(medias_similaridade_dataset)), medias_similaridade_dataset, color='skyblue')\n",
        "plt.xlabel(\"Entradas no Dataset\")\n",
        "plt.ylabel(\"Média de Similaridade dos Chunks Relevantes\")\n",
        "plt.title(\"Média de Similaridade dos Chunks Relevantes por Entrada no Dataset\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "sOZ6RTNTGiiG",
        "outputId": "9f2b5d66-c5f3-4c9f-c107-2b7547506a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-Processamento dos Chunks"
      ],
      "metadata": {
        "id": "nHPSW63DOGbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "\n",
        "# Carregar o modelo e tokenizer do Pegasus\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n",
        "\n",
        "# Função para concatenar chunks mais relevantes\n",
        "def concatenar_chunks_relevantes(entrada, num_chunks=5, max_chars=4096):\n",
        "    \"\"\"\n",
        "    Concatena os 'num_chunks' mais relevantes de uma entrada específica para formar um texto único para sumarização.\n",
        "    \"\"\"\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks[:num_chunks]]\n",
        "    texto_concatenado = \" \".join(chunks_textos)\n",
        "    return texto_concatenado[:max_chars]\n",
        "\n",
        "# Função para gerar o resumo com Pegasus\n",
        "def gerar_resumo(texto):\n",
        "    \"\"\"\n",
        "    Gera um resumo usando o modelo Pegasus para um texto fornecido.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, max_length=4096, padding=\"longest\")\n",
        "    summary_ids = model.generate(inputs.input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
        "    resumo = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return resumo\n",
        "\n",
        "# Função para exibir o resultado formatado\n",
        "def exibir_resultado_formatado(entrada):\n",
        "    # Informações principais\n",
        "    survey_id = entrada.get('survey_id', 'N/A')\n",
        "    survey_title = entrada.get('survey_title', 'N/A')\n",
        "    section_title = entrada.get('section_title', 'N/A')\n",
        "    section_text_referencia = entrada.get('section_text_in_survey', 'N/A')\n",
        "\n",
        "    # Concatenar os chunks e gerar o resumo\n",
        "    texto_concatenado = concatenar_chunks_relevantes(entrada, num_chunks=5)\n",
        "    resumo_gerado = gerar_resumo(texto_concatenado)\n",
        "\n",
        "    # Impressão formatada\n",
        "    print(\"═\" * 60)\n",
        "    print(f\"**Survey ID:** {survey_id}\")\n",
        "    print(f\"**Survey Title:** {survey_title}\")\n",
        "    print(f\"**Section Title:** {section_title}\")\n",
        "    print(\"═\" * 60)\n",
        "\n",
        "    print(\"\\n**Section Text in Survey (Referência):**\")\n",
        "    print(f\"> {section_text_referencia}\\n\")\n",
        "\n",
        "    print(\"═\" * 60)\n",
        "    print(\"**Resumo Gerado:**\")\n",
        "    print(f\"> {resumo_gerado}\\n\")\n",
        "    print(\"═\" * 60)\n",
        "\n",
        "# Teste do código com uma entrada específica\n",
        "entrada_exemplo = dataset['train'][1]  # Seleciona uma entrada do dataset\n",
        "exibir_resultado_formatado(entrada_exemplo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTydS4NwfOF7",
        "outputId": "c82a9373-0e10-4118-d7ed-8d737dba4dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "════════════════════════════════════════════════════════════\n",
            "**Survey ID:** 2309.15402v1\n",
            "**Survey Title:** A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future\n",
            "**Section Title:** Discussion::Comparison between Verification/Refinement and Planning\n",
            "════════════════════════════════════════════════════════════\n",
            "\n",
            "**Section Text in Survey (Referência):**\n",
            "> Numerous parallels exist between planning methods and verification/refinement-based methods, as both rely on feedback from intermediate processes to adjust and refine behavior. The distinction lies in the fact that planning methods encompass decision-making, while verification/refinement-based methods solely address intermediate errors without delving into higher-level cognitive processes. LLM reasoning processes are often hallucinatory, causing factual and logical mistakes. Verify and edit based methods BIBREF70 , BIBREF104 , BIBREF71 , BIBREF82 verify the correctness of the reasoning process and refine reasoning step that may cause hallucinatory. Through verification and refinement, cascading errors and hallucinatory phenomena in the reasoning process are significantly reduced. The planning methods BIBREF80 , BIBREF16 , BIBREF81 , BIBREF127 , BIBREF82 , BIBREF166 introduce a decision-making process in the reasoning. They evaluate the intermediate reasoning steps to get feedback, and based on the feedback, they engage in exploration and backtracking to achieve superior solutions at a global level. Their specialization lies in handling complex problems, enabling them to achieve remarkable performance, especially when confronted with intricate multi-hop reasoning and planning tasks.\n",
            "\n",
            "════════════════════════════════════════════════════════════\n",
            "**Resumo Gerado:**\n",
            "> Deductive Verification of Chain-of-Thought Reasoning Zhan Ling1 Yunnhao Fang1 Xuanlin Li1 Zhiao Huang1 Mingu Lee2 Roland Memisevic2 Hao Su1 1UC San Diego, 2Qualcomm AI Research Abstract Large Language Models (LLMs) significantly benefit from Chain-of-Thought (CoT) prompting in performing various reasoning tasks. While CoT allows models to produce more comprehensive reasoning processes, its emphasis on intermediate reasoning steps can inadvertently introduce hallucinations and accumulated errors, thereby limiting models’ ability to solve complex reasoning tasks. Inspired by how humans engage in careful and meticulous deductive logical reasoning processes to solve tasks, we seek to enable language models to perform explicit and rigorous deductive reasoning, and also ensure the trustworthiness of their reasoning process through self-verification. In light of this, we propose to decompose a reasoning verification process into a series of step-by-step subprocesses, however,...CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge.\n",
            "\n",
            "════════════════════════════════════════════════════════════\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "\n",
        "# Configuração do modelo Pegasus\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n",
        "\n",
        "# Função para concatenar chunks mais relevantes\n",
        "def concatenar_chunks_relevantes(entrada, num_chunks=5, max_chars=4096):\n",
        "    \"\"\"\n",
        "    Concatena os 'num_chunks' mais relevantes de uma entrada específica para formar um texto único para sumarização.\n",
        "\n",
        "    Parâmetros:\n",
        "    - entrada: dicionário com os dados de uma seção do dataset.\n",
        "    - num_chunks: número de chunks mais relevantes a serem concatenados.\n",
        "    - max_chars: limite de caracteres para a entrada concatenada.\n",
        "\n",
        "    Retorna:\n",
        "    - texto_concatenado: string com os chunks mais relevantes concatenados até o limite especificado.\n",
        "    \"\"\"\n",
        "    # Obter os chunks e selecionar os mais relevantes (primeiros 'num_chunks')\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks[:num_chunks]]\n",
        "\n",
        "    # Concatenar todos os chunks em um único texto\n",
        "    texto_concatenado = \" \".join(chunks_textos)\n",
        "\n",
        "    # Limitar o comprimento do texto concatenado\n",
        "    return texto_concatenado[:max_chars]\n",
        "\n",
        "# Função para gerar o resumo com Pegasus\n",
        "def gerar_resumo(texto):\n",
        "    \"\"\"\n",
        "    Gera um resumo usando o modelo Pegasus para um texto fornecido.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto: string contendo o texto a ser resumido.\n",
        "\n",
        "    Retorna:\n",
        "    - resumo: string com o resumo gerado.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, max_length=4096, padding=\"longest\")\n",
        "    summary_ids = model.generate(inputs.input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
        "    resumo = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return resumo\n",
        "\n",
        "# Função para calcular a métrica de fidelidade\n",
        "def check_eval_fidelidade(texto_referencia, resumo_gerado):\n",
        "    \"\"\"\n",
        "    Calcula uma métrica de fidelidade básica comparando o texto de referência com o resumo gerado.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto_referencia: string com o texto original de referência.\n",
        "    - resumo_gerado: string com o resumo gerado para comparação.\n",
        "\n",
        "    Retorna:\n",
        "    - fidelidade: float representando a fidelidade entre o resumo e o texto de referência.\n",
        "    \"\"\"\n",
        "    interseccao = set(texto_referencia.split()).intersection(set(resumo_gerado.split()))\n",
        "    fidelidade = len(interseccao) / len(set(texto_referencia.split())) if texto_referencia else 0\n",
        "    return fidelidade\n",
        "\n",
        "# Exemplo usando o train[1]\n",
        "entrada_exemplo = dataset['train'][2]  # Seleciona uma entrada do dataset\n",
        "texto_referencia = entrada_exemplo['section_text_in_survey']  # Acessa o texto de referência completo\n",
        "texto_concatenado = concatenar_chunks_relevantes(entrada_exemplo, num_chunks=5)  # Concatena os chunks relevantes\n",
        "resumo_gerado = gerar_resumo(texto_concatenado)  # Gera o resumo\n",
        "\n",
        "# Calcular a fidelidade\n",
        "fidelidade = check_eval_fidelidade(texto_referencia, resumo_gerado)\n",
        "\n",
        "# Impressão dos resultados\n",
        "print(\"═\" * 50)\n",
        "print(\"📑 **Resumo da Seção** 📑\\n\")\n",
        "print(\"**Título da Seção:**\", entrada_exemplo['section_title'])\n",
        "print(\"\\n**Section Text in Survey (Referência):**\\n\")\n",
        "print(texto_referencia)\n",
        "print(\"\\n\" + \"═\" * 50)\n",
        "print(\"**Resumo Gerado:**\\n\")\n",
        "print(resumo_gerado)\n",
        "print(\"═\" * 50)\n",
        "print(f\"\\nFidelidade entre o texto de referência e o resumo gerado: {fidelidade:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92NOEcgtnLOO",
        "outputId": "476a4df3-cb75-4306-9dca-13b66ac03ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "══════════════════════════════════════════════════\n",
            "📑 **Resumo da Seção** 📑\n",
            "\n",
            "**Título da Seção:** Methods::XoT Structural Variants::Tree Structure\n",
            "\n",
            "**Section Text in Survey (Referência):**\n",
            "\n",
            "The original chain structure inherently limits the scope of exploration. Through the incorporation of tree structures and tree search algorithms, models gain the capability to efficiently explore and backtrack during the reasoning process BIBREF80 , BIBREF16 , as shown in Figure FIGREF24 (e). Combined with self-assessment of intermediate thoughts, models can achieve global optimum solutions. However, the current tree-of-thought has considerable limitations on task selection and requires specific prompt designing for each task, which hinders its widespread application. SoT BIBREF14 is another variant of the tree structure, which decomposes a problem into subproblems that can be processed in parallel and solved at the same time to speed up reasoning. However, its utility is restricted to parallel decomposable problems and is not suited for complex reasoning tasks.\n",
            "\n",
            "══════════════════════════════════════════════════\n",
            "**Resumo Gerado:**\n",
            "\n",
            "...representative example, the Chain-of-Thought prompts largely improve the performance on tasks that require logical reasoning by simply providing a “Let’s think step by step” (Kojima et al., 2022) instruction or a few demonstrations (Wei et al., 2022). Another topic that arises quite a surge of interests is to prompt LLMs to help finish complex multi-modality task (Shen et al., 2023; Zhu et al., 2023). For example, HuggingGPT (Shen et al., 2023) design prompts to guide the LLM to generate structural JSON for the orchestration of multi-model execution to finish complex tasks.\n",
            "══════════════════════════════════════════════════\n",
            "\n",
            "Fidelidade entre o texto de referência e o resumo gerado: 0.1340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "\n",
        "# Função para calcular a métrica de fidelidade\n",
        "def check_eval_fidelidade(texto_referencia, resumo_gerado):\n",
        "    \"\"\"\n",
        "    Calcula uma métrica de fidelidade básica comparando o texto de referência com o resumo gerado.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto_referencia: string com o texto original de referência.\n",
        "    - resumo_gerado: string com o resumo gerado para comparação.\n",
        "\n",
        "    Retorna:\n",
        "    - fidelidade: float representando a fidelidade entre o resumo e o texto de referência.\n",
        "    \"\"\"\n",
        "    interseccao = set(texto_referencia.split()).intersection(set(resumo_gerado.split()))\n",
        "    fidelidade = len(interseccao) / len(set(texto_referencia.split())) if texto_referencia else 0\n",
        "    return fidelidade\n",
        "\n",
        "# Configuração do modelo Pegasus\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n",
        "\n",
        "# Função para concatenar chunks mais relevantes\n",
        "def concatenar_chunks_relevantes(entrada, num_chunks=5, max_chars=4096):\n",
        "    \"\"\"\n",
        "    Concatena os 'num_chunks' mais relevantes de uma entrada específica para formar um texto único para sumarização.\n",
        "\n",
        "    Parâmetros:\n",
        "    - entrada: dicionário com os dados de uma seção do dataset.\n",
        "    - num_chunks: número de chunks mais relevantes a serem concatenados.\n",
        "    - max_chars: limite de caracteres para a entrada concatenada.\n",
        "\n",
        "    Retorna:\n",
        "    - texto_concatenado: string com os chunks mais relevantes concatenados até o limite especificado.\n",
        "    \"\"\"\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks[:num_chunks]]\n",
        "    texto_concatenado = \" \".join(chunks_textos)\n",
        "    return texto_concatenado[:max_chars]\n",
        "\n",
        "# Exemplo usando o train[1]\n",
        "entrada_exemplo = dataset['train'][1]  # Seleciona uma entrada do dataset\n",
        "texto_referencia = entrada_exemplo['section_text_in_survey']  # Acessa o texto de referência completo\n",
        "texto_para_resumo = concatenar_chunks_relevantes(entrada_exemplo, num_chunks=5)  # Concatena os chunks relevantes\n",
        "\n",
        "# Gerar o resumo usando Pegasus\n",
        "inputs = tokenizer(texto_para_resumo, return_tensors=\"pt\", truncation=True, max_length=4096, padding=\"longest\")\n",
        "summary_ids = model.generate(inputs.input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
        "resumo_gerado = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Calcular a fidelidade\n",
        "fidelidade = check_eval_fidelidade(texto_referencia, resumo_gerado)\n",
        "\n",
        "# Impressão dos resultados\n",
        "print(\"═\" * 50)\n",
        "print(\"📑 **Resumo da Seção** 📑\\n\")\n",
        "print(\"**Título da Seção:**\", entrada_exemplo['section_title'])\n",
        "print(\"\\n**Section Text in Survey (Referência):**\\n\")\n",
        "print(texto_referencia)\n",
        "print(\"\\n\" + \"═\" * 50)\n",
        "print(\"**Resumo Gerado:**\\n\")\n",
        "print(resumo_gerado)\n",
        "print(\"═\" * 50)\n",
        "print(f\"\\nFidelidade entre o texto de referência e o resumo gerado: {fidelidade:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdH3GptPpKQe",
        "outputId": "f2a18c02-1882-493b-82ec-c465d88ecb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "══════════════════════════════════════════════════\n",
            "📑 **Resumo da Seção** 📑\n",
            "\n",
            "**Título da Seção:** Discussion::Comparison between Verification/Refinement and Planning\n",
            "\n",
            "**Section Text in Survey (Referência):**\n",
            "\n",
            "Numerous parallels exist between planning methods and verification/refinement-based methods, as both rely on feedback from intermediate processes to adjust and refine behavior. The distinction lies in the fact that planning methods encompass decision-making, while verification/refinement-based methods solely address intermediate errors without delving into higher-level cognitive processes. LLM reasoning processes are often hallucinatory, causing factual and logical mistakes. Verify and edit based methods BIBREF70 , BIBREF104 , BIBREF71 , BIBREF82 verify the correctness of the reasoning process and refine reasoning step that may cause hallucinatory. Through verification and refinement, cascading errors and hallucinatory phenomena in the reasoning process are significantly reduced. The planning methods BIBREF80 , BIBREF16 , BIBREF81 , BIBREF127 , BIBREF82 , BIBREF166 introduce a decision-making process in the reasoning. They evaluate the intermediate reasoning steps to get feedback, and based on the feedback, they engage in exploration and backtracking to achieve superior solutions at a global level. Their specialization lies in handling complex problems, enabling them to achieve remarkable performance, especially when confronted with intricate multi-hop reasoning and planning tasks.\n",
            "\n",
            "══════════════════════════════════════════════════\n",
            "**Resumo Gerado:**\n",
            "\n",
            "Deductive Verification of Chain-of-Thought Reasoning Zhan Ling1 Yunnhao Fang1 Xuanlin Li1 Zhiao Huang1 Mingu Lee2 Roland Memisevic2 Hao Su1 1UC San Diego, 2Qualcomm AI Research Abstract Large Language Models (LLMs) significantly benefit from Chain-of-Thought (CoT) prompting in performing various reasoning tasks. While CoT allows models to produce more comprehensive reasoning processes, its emphasis on intermediate reasoning steps can inadvertently introduce hallucinations and accumulated errors, thereby limiting models’ ability to solve complex reasoning tasks. Inspired by how humans engage in careful and meticulous deductive logical reasoning processes to solve tasks, we seek to enable language models to perform explicit and rigorous deductive reasoning, and also ensure the trustworthiness of their reasoning process through self-verification. In light of this, we propose to decompose a reasoning verification process into a series of step-by-step subprocesses, however,...CoT prompting, which seeks to increase prediction factuality by post-editing reasoning chains according to external knowledge.\n",
            "══════════════════════════════════════════════════\n",
            "\n",
            "Fidelidade entre o texto de referência e o resumo gerado: 0.1858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Função para calcular as métricas ROUGE\n",
        "def calcular_rouge(texto_referencia, resumo_gerado):\n",
        "    \"\"\"\n",
        "    Calcula as métricas ROUGE-1, ROUGE-2 e ROUGE-L entre o texto de referência e o resumo gerado.\n",
        "\n",
        "    Parâmetros:\n",
        "    - texto_referencia: string com o texto original de referência.\n",
        "    - resumo_gerado: string com o resumo gerado para comparação.\n",
        "\n",
        "    Retorna:\n",
        "    - dicionário com as pontuações ROUGE-1, ROUGE-2 e ROUGE-L.\n",
        "    \"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    pontuacoes = scorer.score(texto_referencia, resumo_gerado)\n",
        "    return pontuacoes\n",
        "\n",
        "# Função para concatenar chunks mais relevantes\n",
        "def concatenar_chunks_relevantes(entrada, num_chunks=5, max_chars=4096):\n",
        "    \"\"\"\n",
        "    Concatena os 'num_chunks' mais relevantes de uma entrada específica para formar um texto único para sumarização.\n",
        "\n",
        "    Parâmetros:\n",
        "    - entrada: dicionário com os dados de uma seção do dataset.\n",
        "    - num_chunks: número de chunks mais relevantes a serem concatenados.\n",
        "    - max_chars: limite de caracteres para a entrada concatenada.\n",
        "\n",
        "    Retorna:\n",
        "    - texto_concatenado: string com os chunks mais relevantes concatenados até o limite especificado.\n",
        "    \"\"\"\n",
        "    # Obter os chunks e selecionar os mais relevantes (simplesmente os primeiros 'num_chunks')\n",
        "    chunks = entrada['generated_section_text']['autosurvey_t5_3b_10_chunks']['references_sent_to_gpt']\n",
        "    chunks_textos = [chunk['chunk'] for chunk in chunks[:num_chunks]]\n",
        "\n",
        "    # Concatenar todos os chunks em um único texto\n",
        "    texto_concatenado = \" \".join(chunks_textos)\n",
        "\n",
        "    # Limitar o comprimento do texto concatenado\n",
        "    return texto_concatenado[:max_chars]\n",
        "\n",
        "# Configuração do modelo Pegasus\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n",
        "\n",
        "# Exemplo usando uma entrada automática do dataset\n",
        "entrada_exemplo = dataset['train'][1]\n",
        "texto_referencia = entrada_exemplo['section_text_in_survey']  # Acessa o texto de referência completo\n",
        "texto_para_resumo = concatenar_chunks_relevantes(entrada_exemplo, num_chunks=5)  # Concatena os chunks relevantes\n",
        "\n",
        "# Gerar o resumo usando Pegasus\n",
        "inputs = tokenizer(texto_para_resumo, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
        "summary_ids = model.generate(inputs.input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
        "resumo_gerado = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Calcular ROUGE\n",
        "pontuacoes_rouge = calcular_rouge(texto_referencia, resumo_gerado)\n",
        "\n",
        "# Exibir as pontuações ROUGE\n",
        "print(\"══════════════════════════════════════════════════\")\n",
        "print(\"📊 **Métricas ROUGE** 📊\")\n",
        "print(f\"ROUGE-1 (precisão): {pontuacoes_rouge['rouge1'].precision:.4f}\")\n",
        "print(f\"ROUGE-1 (recall): {pontuacoes_rouge['rouge1'].recall:.4f}\")\n",
        "print(f\"ROUGE-1 (F1): {pontuacoes_rouge['rouge1'].fmeasure:.4f}\\n\")\n",
        "\n",
        "print(f\"ROUGE-2 (precisão): {pontuacoes_rouge['rouge2'].precision:.4f}\")\n",
        "print(f\"ROUGE-2 (recall): {pontuacoes_rouge['rouge2'].recall:.4f}\")\n",
        "print(f\"ROUGE-2 (F1): {pontuacoes_rouge['rouge2'].fmeasure:.4f}\\n\")\n",
        "\n",
        "print(f\"ROUGE-L (precisão): {pontuacoes_rouge['rougeL'].precision:.4f}\")\n",
        "print(f\"ROUGE-L (recall): {pontuacoes_rouge['rougeL'].recall:.4f}\")\n",
        "print(f\"ROUGE-L (F1): {pontuacoes_rouge['rougeL'].fmeasure:.4f}\")\n",
        "print(\"══════════════════════════════════════════════════\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rmENn0wqVuL",
        "outputId": "6cce6528-6510-4ab5-a644-ac925f1f9715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "══════════════════════════════════════════════════\n",
            "📊 **Métricas ROUGE** 📊\n",
            "ROUGE-1 (precisão): 0.3205\n",
            "ROUGE-1 (recall): 0.2907\n",
            "ROUGE-1 (F1): 0.3049\n",
            "\n",
            "ROUGE-2 (precisão): 0.0516\n",
            "ROUGE-2 (recall): 0.0468\n",
            "ROUGE-2 (F1): 0.0491\n",
            "\n",
            "ROUGE-L (precisão): 0.1474\n",
            "ROUGE-L (recall): 0.1337\n",
            "ROUGE-L (F1): 0.1402\n",
            "══════════════════════════════════════════════════\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "Pc9ZpsRP5iDS"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8Z/ewS7xLwwNMFQr2eX2F"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}